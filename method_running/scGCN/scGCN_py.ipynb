{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7747aae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                      Version\n",
      "---------------------------- ------------\n",
      "absl-py                      1.0.0\n",
      "adabelief-pytorch            0.2.0\n",
      "aiohttp                      3.8.1\n",
      "aiosignal                    1.2.0\n",
      "anndata                      0.7.8\n",
      "anndata2ri                   1.0.6\n",
      "annoy                        1.17.0\n",
      "anyio                        3.5.0\n",
      "argon2-cffi                  21.3.0\n",
      "argon2-cffi-bindings         21.2.0\n",
      "asttokens                    2.0.5\n",
      "astunparse                   1.6.3\n",
      "async-timeout                4.0.2\n",
      "attrs                        21.4.0\n",
      "Babel                        2.9.1\n",
      "backcall                     0.2.0\n",
      "backports.zoneinfo           0.2.1\n",
      "bbknn                        1.5.1\n",
      "biothings-client             0.2.6\n",
      "bleach                       4.1.0\n",
      "cachetools                   5.0.0\n",
      "certifi                      2021.10.8\n",
      "cffi                         1.15.0\n",
      "charset-normalizer           2.0.12\n",
      "chex                         0.1.1\n",
      "click                        8.0.4\n",
      "colorama                     0.4.4\n",
      "commonmark                   0.9.1\n",
      "cryptography                 37.0.2\n",
      "cycler                       0.11.0\n",
      "Cython                       0.29.28\n",
      "debugpy                      1.5.1\n",
      "decorator                    5.1.1\n",
      "defusedxml                   0.7.1\n",
      "dm-tree                      0.1.6\n",
      "docrep                       0.3.2\n",
      "docutils                     0.18.1\n",
      "dunamai                      1.9.0\n",
      "entrypoints                  0.4\n",
      "et-xmlfile                   1.1.0\n",
      "executing                    0.8.3\n",
      "fastcluster                  1.2.6\n",
      "flatbuffers                  1.12\n",
      "flax                         0.4.0\n",
      "fonttools                    4.29.1\n",
      "frozenlist                   1.3.0\n",
      "fsspec                       2022.2.0\n",
      "future                       0.18.2\n",
      "gast                         0.3.3\n",
      "get_version                  3.5.4\n",
      "google-auth                  2.6.0\n",
      "google-auth-oauthlib         0.4.6\n",
      "google-pasta                 0.2.0\n",
      "grpcio                       1.44.0\n",
      "h5py                         2.10.0\n",
      "harmonypy                    0.0.6\n",
      "idna                         3.3\n",
      "igraph                       0.9.9\n",
      "imap                         1.0.0\n",
      "importlib-metadata           4.11.2\n",
      "importlib-resources          5.4.0\n",
      "ipykernel                    6.9.1\n",
      "ipython                      8.1.1\n",
      "ipython-genutils             0.2.0\n",
      "ipywidgets                   7.6.5\n",
      "jax                          0.3.1\n",
      "jaxlib                       0.1.75\n",
      "jedi                         0.18.1\n",
      "jeepney                      0.8.0\n",
      "Jinja2                       3.0.3\n",
      "joblib                       1.1.0\n",
      "json5                        0.9.6\n",
      "jsonschema                   4.4.0\n",
      "jupyter-client               7.1.2\n",
      "jupyter-core                 4.9.2\n",
      "jupyter-server               1.13.5\n",
      "jupyterlab                   3.3.0\n",
      "jupyterlab-pygments          0.1.2\n",
      "jupyterlab-server            2.10.3\n",
      "jupyterlab-widgets           1.0.2\n",
      "keras                        2.9.0\n",
      "Keras-Preprocessing          1.1.2\n",
      "keyring                      23.5.0\n",
      "kiwisolver                   1.3.2\n",
      "leidenalg                    0.8.9\n",
      "libclang                     14.0.1\n",
      "llvmlite                     0.38.0\n",
      "loompy                       3.0.6\n",
      "louvain                      0.7.1\n",
      "Markdown                     3.3.6\n",
      "MarkupSafe                   2.1.0\n",
      "matplotlib                   3.5.1\n",
      "matplotlib-inline            0.1.3\n",
      "mistune                      0.8.4\n",
      "mnnpy                        0.1.9.5\n",
      "msgpack                      1.0.3\n",
      "multidict                    6.0.2\n",
      "multipledispatch             0.6.0\n",
      "mygene                       3.2.2\n",
      "natsort                      8.1.0\n",
      "nbclassic                    0.3.6\n",
      "nbclient                     0.5.11\n",
      "nbconvert                    6.4.2\n",
      "nbformat                     5.1.3\n",
      "nest-asyncio                 1.5.4\n",
      "networkx                     2.7\n",
      "notebook                     6.4.8\n",
      "notebook-shim                0.1.0\n",
      "numba                        0.55.1\n",
      "numexpr                      2.8.1\n",
      "numpy                        1.18.1\n",
      "numpy-groupies               0.9.14\n",
      "numpyro                      0.9.1\n",
      "oauthlib                     3.2.0\n",
      "openpyxl                     3.0.9\n",
      "opt-einsum                   3.3.0\n",
      "optax                        0.1.1\n",
      "packaging                    21.3\n",
      "pandas                       1.3.5\n",
      "pandocfilters                1.5.0\n",
      "parso                        0.8.3\n",
      "patsy                        0.5.2\n",
      "pexpect                      4.8.0\n",
      "pickleshare                  0.7.5\n",
      "Pillow                       9.0.1\n",
      "pip                          22.1.2\n",
      "pkginfo                      1.8.2\n",
      "prometheus-client            0.13.1\n",
      "prompt-toolkit               3.0.28\n",
      "protobuf                     3.19.4\n",
      "ptyprocess                   0.7.0\n",
      "pure-eval                    0.2.2\n",
      "pyasn1                       0.4.8\n",
      "pyasn1-modules               0.2.8\n",
      "pycparser                    2.21\n",
      "pyDeprecate                  0.3.1\n",
      "pydot                        1.4.2\n",
      "Pygments                     2.11.2\n",
      "pynndescent                  0.5.6\n",
      "pyparsing                    3.0.7\n",
      "pyro-api                     0.1.2\n",
      "pyro-ppl                     1.8.0\n",
      "pyrsistent                   0.18.1\n",
      "python-dateutil              2.8.2\n",
      "python-igraph                0.9.9\n",
      "pytorch-lightning            1.5.10\n",
      "pytz                         2021.3\n",
      "pytz-deprecation-shim        0.1.0.post0\n",
      "PyYAML                       6.0\n",
      "pyzmq                        22.3.0\n",
      "readme-renderer              35.0\n",
      "requests                     2.27.1\n",
      "requests-oauthlib            1.3.1\n",
      "requests-toolbelt            0.9.1\n",
      "ResPAN                       0.1.0\n",
      "rfc3986                      2.0.0\n",
      "rich                         12.4.1\n",
      "rpy2                         3.4.5\n",
      "rsa                          4.8\n",
      "scanpy                       1.8.2\n",
      "scGCN                        0.0.1\n",
      "scib                         1.0.0\n",
      "scikit-learn                 1.0.2\n",
      "scikit-misc                  0.1.4\n",
      "scipy                        1.4.1\n",
      "scvi-tools                   0.15.0\n",
      "seaborn                      0.11.2\n",
      "SecretStorage                3.3.2\n",
      "Send2Trash                   1.8.0\n",
      "setuptools                   59.5.0\n",
      "sinfo                        0.3.4\n",
      "six                          1.16.0\n",
      "sklearn                      0.0\n",
      "sniffio                      1.2.0\n",
      "stack-data                   0.2.0\n",
      "statsmodels                  0.13.2\n",
      "stdlib-list                  0.8.0\n",
      "tables                       3.6.1\n",
      "tabulate                     0.8.9\n",
      "tensorboard                  2.9.0\n",
      "tensorboard-data-server      0.6.1\n",
      "tensorboard-plugin-wit       1.8.1\n",
      "tensorflow                   2.3.0\n",
      "tensorflow-estimator         2.3.0\n",
      "tensorflow-io-gcs-filesystem 0.26.0\n",
      "termcolor                    1.1.0\n",
      "terminado                    0.13.2\n",
      "testpath                     0.6.0\n",
      "texttable                    1.6.4\n",
      "threadpoolctl                3.1.0\n",
      "toolz                        0.11.2\n",
      "torch                        1.10.2+cu113\n",
      "torchaudio                   0.10.2+cu113\n",
      "torchmetrics                 0.7.2\n",
      "torchvision                  0.11.3+cu113\n",
      "tornado                      6.1\n",
      "tqdm                         4.63.0\n",
      "traitlets                    5.1.1\n",
      "twine                        4.0.0\n",
      "typing_extensions            4.1.1\n",
      "tzdata                       2021.5\n",
      "tzlocal                      4.1\n",
      "umap-learn                   0.5.2\n",
      "urllib3                      1.26.8\n",
      "wcwidth                      0.2.5\n",
      "webencodings                 0.5.1\n",
      "websocket-client             1.3.1\n",
      "Werkzeug                     2.0.3\n",
      "wheel                        0.37.1\n",
      "widgetsnbextension           3.5.2\n",
      "wrapt                        1.14.1\n",
      "xlrd                         1.2.0\n",
      "yarl                         1.7.2\n",
      "zipp                         3.7.0\n"
     ]
    }
   ],
   "source": [
    "! pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a28d9517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from scipy import sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f656b366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "740111ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataPath2 = '/gpfs/gibbs/pi/zhao/yw599/Multiome/scGCN/scGCN/input/Data1.csv'\n",
    "LabelsPath2 = '/gpfs/gibbs/pi/zhao/yw599/Multiome/scGCN/scGCN/input/Label1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "08d6d61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_label2 = pd.read_csv(LabelsPath2, header=0, index_col=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7b66c1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_label2.columns = ['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8205ac3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['beta', 'ductal', 'delta', ..., 'ductal', 'quiescent_stellate',\n",
       "       'ductal'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(lab_label2).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e8f5580",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv(DataPath2, index_col=0, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "66b75d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2810468N07RIK</th>\n",
       "      <th>4632428N05RIK</th>\n",
       "      <th>9430020K01RIK</th>\n",
       "      <th>AF251705</th>\n",
       "      <th>ABCB1A</th>\n",
       "      <th>ABCG2</th>\n",
       "      <th>ABHD12</th>\n",
       "      <th>ABHD3</th>\n",
       "      <th>ABI3</th>\n",
       "      <th>ABLIM1</th>\n",
       "      <th>...</th>\n",
       "      <th>CACNA2D1</th>\n",
       "      <th>METRN</th>\n",
       "      <th>DENND5A</th>\n",
       "      <th>SNAP47</th>\n",
       "      <th>PRICKLE1</th>\n",
       "      <th>GPLD1</th>\n",
       "      <th>CELF3</th>\n",
       "      <th>DLGAP1</th>\n",
       "      <th>BDNF</th>\n",
       "      <th>SNX33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>526</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>404</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>378</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "      <td>253</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7391</th>\n",
       "      <td>0</td>\n",
       "      <td>1537</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7392</th>\n",
       "      <td>0</td>\n",
       "      <td>351</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7393</th>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2523</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7394</th>\n",
       "      <td>0</td>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>346</td>\n",
       "      <td>0</td>\n",
       "      <td>347</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7395</th>\n",
       "      <td>0</td>\n",
       "      <td>2491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2604</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7396 rows × 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      2810468N07RIK  4632428N05RIK  9430020K01RIK  AF251705  ABCB1A  ABCG2  \\\n",
       "0                 0              0              0         0       0      0   \n",
       "1                75              0              0         0       0      0   \n",
       "2              2241              0              0         0       0      0   \n",
       "3                 0            151            130         0     146    378   \n",
       "4                 0              0              0         0       0      0   \n",
       "...             ...            ...            ...       ...     ...    ...   \n",
       "7391              0           1537              0         0       0      0   \n",
       "7392              0            351              0        13       0      3   \n",
       "7393              0            134              0        91       0      0   \n",
       "7394              0            502              0        87       0      0   \n",
       "7395              0           2491              0         0       0      0   \n",
       "\n",
       "      ABHD12  ABHD3  ABI3  ABLIM1  ...  CACNA2D1  METRN  DENND5A  SNAP47  \\\n",
       "0          0     91     0      10  ...        40      3        0       0   \n",
       "1          0    526     0       0  ...         0      0        0     294   \n",
       "2        286      0     1       1  ...         0      0      404       2   \n",
       "3        155      0    53      50  ...         0      0       76       0   \n",
       "4        143    253     0       3  ...         0      7        0       0   \n",
       "...      ...    ...   ...     ...  ...       ...    ...      ...     ...   \n",
       "7391       9      0   100       0  ...         0      0        0       0   \n",
       "7392     637      0    59       0  ...         0      0        7       0   \n",
       "7393    2523      0   223       1  ...         0      1      126       0   \n",
       "7394     346      0   347       0  ...         0      0        0       0   \n",
       "7395    2604      0   141       0  ...         0      0        3       0   \n",
       "\n",
       "      PRICKLE1  GPLD1  CELF3  DLGAP1  BDNF  SNX33  \n",
       "0            0      0      0       0     0      0  \n",
       "1            0      0      0       0     0      0  \n",
       "2           10      0      0       0     0      0  \n",
       "3           16      0      0       0     0      0  \n",
       "4            0      0      0       6     0     63  \n",
       "...        ...    ...    ...     ...   ...    ...  \n",
       "7391         0      0      0       0     0      0  \n",
       "7392         0      0      0       0     0      0  \n",
       "7393         0      0      0       0     0      0  \n",
       "7394         0      0      0       0     0      0  \n",
       "7395         0      0      0       0     0      0  \n",
       "\n",
       "[7396 rows x 2000 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0ff6b512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2810468N07RIK</th>\n",
       "      <th>4632428N05RIK</th>\n",
       "      <th>9430020K01RIK</th>\n",
       "      <th>AF251705</th>\n",
       "      <th>ABCB1A</th>\n",
       "      <th>ABCG2</th>\n",
       "      <th>ABHD12</th>\n",
       "      <th>ABHD3</th>\n",
       "      <th>ABI3</th>\n",
       "      <th>ABLIM1</th>\n",
       "      <th>...</th>\n",
       "      <th>CACNA2D1</th>\n",
       "      <th>METRN</th>\n",
       "      <th>DENND5A</th>\n",
       "      <th>SNAP47</th>\n",
       "      <th>PRICKLE1</th>\n",
       "      <th>GPLD1</th>\n",
       "      <th>CELF3</th>\n",
       "      <th>DLGAP1</th>\n",
       "      <th>BDNF</th>\n",
       "      <th>SNX33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A1.B003290.3_38_F.1.1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1.B003728.3_56_F.1.1</th>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>526</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1.MAA000560.3_10_M.1.1</th>\n",
       "      <td>2241</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>404</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1.MAA000564.3_10_M.1.1</th>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>130</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>378</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>50</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>A1.MAA000923.3_9_M.1.1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "      <td>253</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P9.MAA000592.3_9_M.1.1</th>\n",
       "      <td>0</td>\n",
       "      <td>1537</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P9.MAA000593.3_8_M.1.1</th>\n",
       "      <td>0</td>\n",
       "      <td>351</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>637</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P9.MAA000603.3_10_M.1.1</th>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2523</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P9.MAA000604.3_10_M.1.1</th>\n",
       "      <td>0</td>\n",
       "      <td>502</td>\n",
       "      <td>0</td>\n",
       "      <td>87</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>346</td>\n",
       "      <td>0</td>\n",
       "      <td>347</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P9.MAA000617.3_10_M.1.1</th>\n",
       "      <td>0</td>\n",
       "      <td>2491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2604</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7396 rows × 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         2810468N07RIK  4632428N05RIK  9430020K01RIK  \\\n",
       "A1.B003290.3_38_F.1.1                0              0              0   \n",
       "A1.B003728.3_56_F.1.1               75              0              0   \n",
       "A1.MAA000560.3_10_M.1.1           2241              0              0   \n",
       "A1.MAA000564.3_10_M.1.1              0            151            130   \n",
       "A1.MAA000923.3_9_M.1.1               0              0              0   \n",
       "...                                ...            ...            ...   \n",
       "P9.MAA000592.3_9_M.1.1               0           1537              0   \n",
       "P9.MAA000593.3_8_M.1.1               0            351              0   \n",
       "P9.MAA000603.3_10_M.1.1              0            134              0   \n",
       "P9.MAA000604.3_10_M.1.1              0            502              0   \n",
       "P9.MAA000617.3_10_M.1.1              0           2491              0   \n",
       "\n",
       "                         AF251705  ABCB1A  ABCG2  ABHD12  ABHD3  ABI3  ABLIM1  \\\n",
       "A1.B003290.3_38_F.1.1           0       0      0       0     91     0      10   \n",
       "A1.B003728.3_56_F.1.1           0       0      0       0    526     0       0   \n",
       "A1.MAA000560.3_10_M.1.1         0       0      0     286      0     1       1   \n",
       "A1.MAA000564.3_10_M.1.1         0     146    378     155      0    53      50   \n",
       "A1.MAA000923.3_9_M.1.1          0       0      0     143    253     0       3   \n",
       "...                           ...     ...    ...     ...    ...   ...     ...   \n",
       "P9.MAA000592.3_9_M.1.1          0       0      0       9      0   100       0   \n",
       "P9.MAA000593.3_8_M.1.1         13       0      3     637      0    59       0   \n",
       "P9.MAA000603.3_10_M.1.1        91       0      0    2523      0   223       1   \n",
       "P9.MAA000604.3_10_M.1.1        87       0      0     346      0   347       0   \n",
       "P9.MAA000617.3_10_M.1.1         0       0      0    2604      0   141       0   \n",
       "\n",
       "                         ...  CACNA2D1  METRN  DENND5A  SNAP47  PRICKLE1  \\\n",
       "A1.B003290.3_38_F.1.1    ...        40      3        0       0         0   \n",
       "A1.B003728.3_56_F.1.1    ...         0      0        0     294         0   \n",
       "A1.MAA000560.3_10_M.1.1  ...         0      0      404       2        10   \n",
       "A1.MAA000564.3_10_M.1.1  ...         0      0       76       0        16   \n",
       "A1.MAA000923.3_9_M.1.1   ...         0      7        0       0         0   \n",
       "...                      ...       ...    ...      ...     ...       ...   \n",
       "P9.MAA000592.3_9_M.1.1   ...         0      0        0       0         0   \n",
       "P9.MAA000593.3_8_M.1.1   ...         0      0        7       0         0   \n",
       "P9.MAA000603.3_10_M.1.1  ...         0      1      126       0         0   \n",
       "P9.MAA000604.3_10_M.1.1  ...         0      0        0       0         0   \n",
       "P9.MAA000617.3_10_M.1.1  ...         0      0        3       0         0   \n",
       "\n",
       "                         GPLD1  CELF3  DLGAP1  BDNF  SNX33  \n",
       "A1.B003290.3_38_F.1.1        0      0       0     0      0  \n",
       "A1.B003728.3_56_F.1.1        0      0       0     0      0  \n",
       "A1.MAA000560.3_10_M.1.1      0      0       0     0      0  \n",
       "A1.MAA000564.3_10_M.1.1      0      0       0     0      0  \n",
       "A1.MAA000923.3_9_M.1.1       0      0       6     0     63  \n",
       "...                        ...    ...     ...   ...    ...  \n",
       "P9.MAA000592.3_9_M.1.1       0      0       0     0      0  \n",
       "P9.MAA000593.3_8_M.1.1       0      0       0     0      0  \n",
       "P9.MAA000603.3_10_M.1.1      0      0       0     0      0  \n",
       "P9.MAA000604.3_10_M.1.1      0      0       0     0      0  \n",
       "P9.MAA000617.3_10_M.1.1      0      0       0     0      0  \n",
       "\n",
       "[7396 rows x 2000 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8d316773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mouse1_lib1.final_cell_0001',\n",
       " 'mouse1_lib1.final_cell_0002',\n",
       " 'mouse1_lib1.final_cell_0003',\n",
       " 'mouse1_lib1.final_cell_0005',\n",
       " 'mouse1_lib1.final_cell_0006',\n",
       " 'mouse1_lib1.final_cell_0007',\n",
       " 'mouse1_lib1.final_cell_0008',\n",
       " 'mouse1_lib1.final_cell_0009',\n",
       " 'mouse1_lib1.final_cell_0010',\n",
       " 'mouse1_lib1.final_cell_0011',\n",
       " 'mouse1_lib1.final_cell_0012',\n",
       " 'mouse1_lib1.final_cell_0013',\n",
       " 'mouse1_lib1.final_cell_0014',\n",
       " 'mouse1_lib1.final_cell_0015',\n",
       " 'mouse1_lib1.final_cell_0016',\n",
       " 'mouse1_lib1.final_cell_0017',\n",
       " 'mouse1_lib1.final_cell_0018',\n",
       " 'mouse1_lib1.final_cell_0019',\n",
       " 'mouse1_lib1.final_cell_0020',\n",
       " 'mouse1_lib1.final_cell_0021',\n",
       " 'mouse1_lib1.final_cell_0022',\n",
       " 'mouse1_lib1.final_cell_0023',\n",
       " 'mouse1_lib1.final_cell_0024',\n",
       " 'mouse1_lib1.final_cell_0025',\n",
       " 'mouse1_lib1.final_cell_0026',\n",
       " 'mouse1_lib1.final_cell_0027',\n",
       " 'mouse1_lib1.final_cell_0028',\n",
       " 'mouse1_lib1.final_cell_0029',\n",
       " 'mouse1_lib1.final_cell_0030',\n",
       " 'mouse1_lib1.final_cell_0031',\n",
       " 'mouse1_lib1.final_cell_0032',\n",
       " 'mouse1_lib1.final_cell_0033',\n",
       " 'mouse1_lib1.final_cell_0034',\n",
       " 'mouse1_lib1.final_cell_0035',\n",
       " 'mouse1_lib1.final_cell_0036',\n",
       " 'mouse1_lib1.final_cell_0037',\n",
       " 'mouse1_lib1.final_cell_0038',\n",
       " 'mouse1_lib1.final_cell_0039',\n",
       " 'mouse1_lib1.final_cell_0040',\n",
       " 'mouse1_lib1.final_cell_0041',\n",
       " 'mouse1_lib1.final_cell_0042',\n",
       " 'mouse1_lib1.final_cell_0043',\n",
       " 'mouse1_lib1.final_cell_0044',\n",
       " 'mouse1_lib1.final_cell_0045',\n",
       " 'mouse1_lib1.final_cell_0046',\n",
       " 'mouse1_lib1.final_cell_0047',\n",
       " 'mouse1_lib1.final_cell_0048',\n",
       " 'mouse1_lib1.final_cell_0049',\n",
       " 'mouse1_lib1.final_cell_0050',\n",
       " 'mouse1_lib1.final_cell_0051',\n",
       " 'mouse1_lib1.final_cell_0052',\n",
       " 'mouse1_lib1.final_cell_0053',\n",
       " 'mouse1_lib1.final_cell_0054',\n",
       " 'mouse1_lib1.final_cell_0055',\n",
       " 'mouse1_lib1.final_cell_0056',\n",
       " 'mouse1_lib1.final_cell_0057',\n",
       " 'mouse1_lib1.final_cell_0058',\n",
       " 'mouse1_lib1.final_cell_0059',\n",
       " 'mouse1_lib1.final_cell_0060',\n",
       " 'mouse1_lib1.final_cell_0061',\n",
       " 'mouse1_lib1.final_cell_0062',\n",
       " 'mouse1_lib1.final_cell_0063',\n",
       " 'mouse1_lib1.final_cell_0064',\n",
       " 'mouse1_lib1.final_cell_0065',\n",
       " 'mouse1_lib1.final_cell_0066',\n",
       " 'mouse1_lib1.final_cell_0067',\n",
       " 'mouse1_lib1.final_cell_0068',\n",
       " 'mouse1_lib1.final_cell_0069',\n",
       " 'mouse1_lib1.final_cell_0070',\n",
       " 'mouse1_lib1.final_cell_0071',\n",
       " 'mouse1_lib1.final_cell_0072',\n",
       " 'mouse1_lib1.final_cell_0073',\n",
       " 'mouse1_lib1.final_cell_0074',\n",
       " 'mouse1_lib1.final_cell_0075',\n",
       " 'mouse1_lib1.final_cell_0076',\n",
       " 'mouse1_lib1.final_cell_0077',\n",
       " 'mouse1_lib1.final_cell_0078',\n",
       " 'mouse1_lib1.final_cell_0079',\n",
       " 'mouse1_lib1.final_cell_0080',\n",
       " 'mouse1_lib1.final_cell_0081',\n",
       " 'mouse1_lib1.final_cell_0082',\n",
       " 'mouse1_lib1.final_cell_0083',\n",
       " 'mouse1_lib1.final_cell_0084',\n",
       " 'mouse1_lib1.final_cell_0085',\n",
       " 'mouse1_lib1.final_cell_0086',\n",
       " 'mouse1_lib1.final_cell_0087',\n",
       " 'mouse1_lib1.final_cell_0088',\n",
       " 'mouse1_lib1.final_cell_0089',\n",
       " 'mouse1_lib1.final_cell_0090',\n",
       " 'mouse1_lib1.final_cell_0091',\n",
       " 'mouse1_lib1.final_cell_0092',\n",
       " 'mouse1_lib1.final_cell_0093',\n",
       " 'mouse1_lib1.final_cell_0094',\n",
       " 'mouse1_lib1.final_cell_0095',\n",
       " 'mouse1_lib1.final_cell_0096',\n",
       " 'mouse1_lib1.final_cell_0097',\n",
       " 'mouse1_lib1.final_cell_0098',\n",
       " 'mouse1_lib1.final_cell_0099',\n",
       " 'mouse1_lib1.final_cell_0100',\n",
       " 'mouse1_lib1.final_cell_0101',\n",
       " 'mouse1_lib1.final_cell_0102',\n",
       " 'mouse1_lib1.final_cell_0103',\n",
       " 'mouse1_lib1.final_cell_0104',\n",
       " 'mouse1_lib1.final_cell_0105',\n",
       " 'mouse1_lib1.final_cell_0106',\n",
       " 'mouse1_lib1.final_cell_0107',\n",
       " 'mouse1_lib1.final_cell_0108',\n",
       " 'mouse1_lib1.final_cell_0109',\n",
       " 'mouse1_lib1.final_cell_0110',\n",
       " 'mouse1_lib1.final_cell_0111',\n",
       " 'mouse1_lib1.final_cell_0112',\n",
       " 'mouse1_lib1.final_cell_0113',\n",
       " 'mouse1_lib1.final_cell_0114',\n",
       " 'mouse1_lib1.final_cell_0115',\n",
       " 'mouse1_lib1.final_cell_0116',\n",
       " 'mouse1_lib1.final_cell_0117',\n",
       " 'mouse1_lib1.final_cell_0118',\n",
       " 'mouse1_lib1.final_cell_0119',\n",
       " 'mouse1_lib1.final_cell_0120',\n",
       " 'mouse1_lib1.final_cell_0121',\n",
       " 'mouse1_lib1.final_cell_0122',\n",
       " 'mouse1_lib1.final_cell_0123',\n",
       " 'mouse1_lib1.final_cell_0124',\n",
       " 'mouse1_lib1.final_cell_0125',\n",
       " 'mouse1_lib1.final_cell_0126',\n",
       " 'mouse1_lib1.final_cell_0127',\n",
       " 'mouse1_lib1.final_cell_0128',\n",
       " 'mouse1_lib1.final_cell_0129',\n",
       " 'mouse1_lib1.final_cell_0130',\n",
       " 'mouse1_lib1.final_cell_0131',\n",
       " 'mouse1_lib1.final_cell_0132',\n",
       " 'mouse1_lib1.final_cell_0133',\n",
       " 'mouse1_lib1.final_cell_0134',\n",
       " 'mouse1_lib1.final_cell_0135',\n",
       " 'mouse1_lib1.final_cell_0136',\n",
       " 'mouse1_lib1.final_cell_0137',\n",
       " 'mouse1_lib1.final_cell_0138',\n",
       " 'mouse1_lib1.final_cell_0139',\n",
       " 'mouse1_lib1.final_cell_0140',\n",
       " 'mouse1_lib1.final_cell_0141',\n",
       " 'mouse1_lib1.final_cell_0142',\n",
       " 'mouse1_lib1.final_cell_0143',\n",
       " 'mouse1_lib1.final_cell_0144',\n",
       " 'mouse1_lib1.final_cell_0145',\n",
       " 'mouse1_lib1.final_cell_0146',\n",
       " 'mouse1_lib1.final_cell_0147',\n",
       " 'mouse1_lib1.final_cell_0148',\n",
       " 'mouse1_lib1.final_cell_0149',\n",
       " 'mouse1_lib1.final_cell_0150',\n",
       " 'mouse1_lib1.final_cell_0151',\n",
       " 'mouse1_lib1.final_cell_0152',\n",
       " 'mouse1_lib1.final_cell_0153',\n",
       " 'mouse1_lib1.final_cell_0154',\n",
       " 'mouse1_lib1.final_cell_0155',\n",
       " 'mouse1_lib1.final_cell_0156',\n",
       " 'mouse1_lib1.final_cell_0157',\n",
       " 'mouse1_lib1.final_cell_0158',\n",
       " 'mouse1_lib1.final_cell_0159',\n",
       " 'mouse1_lib1.final_cell_0160',\n",
       " 'mouse1_lib1.final_cell_0161',\n",
       " 'mouse1_lib1.final_cell_0163',\n",
       " 'mouse1_lib1.final_cell_0164',\n",
       " 'mouse1_lib1.final_cell_0165',\n",
       " 'mouse1_lib1.final_cell_0166',\n",
       " 'mouse1_lib1.final_cell_0167',\n",
       " 'mouse1_lib1.final_cell_0168',\n",
       " 'mouse1_lib1.final_cell_0169',\n",
       " 'mouse1_lib1.final_cell_0170',\n",
       " 'mouse1_lib1.final_cell_0171',\n",
       " 'mouse1_lib1.final_cell_0172',\n",
       " 'mouse1_lib1.final_cell_0173',\n",
       " 'mouse1_lib1.final_cell_0174',\n",
       " 'mouse1_lib1.final_cell_0175',\n",
       " 'mouse1_lib1.final_cell_0176',\n",
       " 'mouse1_lib1.final_cell_0177',\n",
       " 'mouse1_lib1.final_cell_0178',\n",
       " 'mouse1_lib1.final_cell_0179',\n",
       " 'mouse1_lib1.final_cell_0180',\n",
       " 'mouse1_lib1.final_cell_0181',\n",
       " 'mouse1_lib1.final_cell_0182',\n",
       " 'mouse1_lib1.final_cell_0183',\n",
       " 'mouse1_lib1.final_cell_0184',\n",
       " 'mouse1_lib1.final_cell_0185',\n",
       " 'mouse1_lib1.final_cell_0186',\n",
       " 'mouse1_lib1.final_cell_0187',\n",
       " 'mouse1_lib1.final_cell_0188',\n",
       " 'mouse1_lib1.final_cell_0189',\n",
       " 'mouse1_lib1.final_cell_0190',\n",
       " 'mouse1_lib1.final_cell_0191',\n",
       " 'mouse1_lib1.final_cell_0192',\n",
       " 'mouse1_lib1.final_cell_0193',\n",
       " 'mouse1_lib1.final_cell_0194',\n",
       " 'mouse1_lib1.final_cell_0195',\n",
       " 'mouse1_lib1.final_cell_0196',\n",
       " 'mouse1_lib1.final_cell_0197',\n",
       " 'mouse1_lib1.final_cell_0198',\n",
       " 'mouse1_lib1.final_cell_0199',\n",
       " 'mouse1_lib1.final_cell_0200',\n",
       " 'mouse1_lib1.final_cell_0201',\n",
       " 'mouse1_lib1.final_cell_0202',\n",
       " 'mouse1_lib1.final_cell_0203',\n",
       " 'mouse1_lib1.final_cell_0204',\n",
       " 'mouse1_lib1.final_cell_0205',\n",
       " 'mouse1_lib1.final_cell_0206',\n",
       " 'mouse1_lib1.final_cell_0207',\n",
       " 'mouse1_lib1.final_cell_0208',\n",
       " 'mouse1_lib1.final_cell_0209',\n",
       " 'mouse1_lib1.final_cell_0210',\n",
       " 'mouse1_lib1.final_cell_0211',\n",
       " 'mouse1_lib1.final_cell_0212',\n",
       " 'mouse1_lib1.final_cell_0213',\n",
       " 'mouse1_lib1.final_cell_0214',\n",
       " 'mouse1_lib1.final_cell_0215',\n",
       " 'mouse1_lib1.final_cell_0216',\n",
       " 'mouse1_lib1.final_cell_0217',\n",
       " 'mouse1_lib1.final_cell_0218',\n",
       " 'mouse1_lib1.final_cell_0219',\n",
       " 'mouse1_lib1.final_cell_0220',\n",
       " 'mouse1_lib1.final_cell_0221',\n",
       " 'mouse1_lib1.final_cell_0223',\n",
       " 'mouse1_lib1.final_cell_0224',\n",
       " 'mouse1_lib1.final_cell_0225',\n",
       " 'mouse1_lib1.final_cell_0226',\n",
       " 'mouse1_lib1.final_cell_0227',\n",
       " 'mouse1_lib1.final_cell_0228',\n",
       " 'mouse1_lib1.final_cell_0229',\n",
       " 'mouse1_lib1.final_cell_0230',\n",
       " 'mouse1_lib1.final_cell_0231',\n",
       " 'mouse1_lib1.final_cell_0232',\n",
       " 'mouse1_lib1.final_cell_0233',\n",
       " 'mouse1_lib1.final_cell_0234',\n",
       " 'mouse1_lib1.final_cell_0235',\n",
       " 'mouse1_lib1.final_cell_0236',\n",
       " 'mouse1_lib1.final_cell_0237',\n",
       " 'mouse1_lib1.final_cell_0238',\n",
       " 'mouse1_lib1.final_cell_0239',\n",
       " 'mouse1_lib1.final_cell_0240',\n",
       " 'mouse1_lib1.final_cell_0241',\n",
       " 'mouse1_lib1.final_cell_0242',\n",
       " 'mouse1_lib1.final_cell_0243',\n",
       " 'mouse1_lib1.final_cell_0244',\n",
       " 'mouse1_lib1.final_cell_0245',\n",
       " 'mouse1_lib1.final_cell_0246',\n",
       " 'mouse1_lib1.final_cell_0247',\n",
       " 'mouse1_lib1.final_cell_0248',\n",
       " 'mouse1_lib1.final_cell_0249',\n",
       " 'mouse1_lib1.final_cell_0250',\n",
       " 'mouse1_lib1.final_cell_0251',\n",
       " 'mouse1_lib1.final_cell_0252',\n",
       " 'mouse1_lib1.final_cell_0253',\n",
       " 'mouse1_lib1.final_cell_0254',\n",
       " 'mouse1_lib1.final_cell_0255',\n",
       " 'mouse1_lib1.final_cell_0256',\n",
       " 'mouse1_lib1.final_cell_0257',\n",
       " 'mouse1_lib1.final_cell_0258',\n",
       " 'mouse1_lib1.final_cell_0259',\n",
       " 'mouse1_lib1.final_cell_0260',\n",
       " 'mouse1_lib1.final_cell_0261',\n",
       " 'mouse1_lib1.final_cell_0262',\n",
       " 'mouse1_lib1.final_cell_0264',\n",
       " 'mouse1_lib1.final_cell_0266',\n",
       " 'mouse1_lib1.final_cell_0267',\n",
       " 'mouse1_lib1.final_cell_0268',\n",
       " 'mouse1_lib1.final_cell_0269',\n",
       " 'mouse1_lib1.final_cell_0270',\n",
       " 'mouse1_lib1.final_cell_0271',\n",
       " 'mouse1_lib1.final_cell_0272',\n",
       " 'mouse1_lib1.final_cell_0273',\n",
       " 'mouse1_lib1.final_cell_0274',\n",
       " 'mouse1_lib1.final_cell_0275',\n",
       " 'mouse1_lib1.final_cell_0276',\n",
       " 'mouse1_lib1.final_cell_0277',\n",
       " 'mouse1_lib2.final_cell_0001',\n",
       " 'mouse1_lib2.final_cell_0003',\n",
       " 'mouse1_lib2.final_cell_0004',\n",
       " 'mouse1_lib2.final_cell_0005',\n",
       " 'mouse1_lib2.final_cell_0006',\n",
       " 'mouse1_lib2.final_cell_0007',\n",
       " 'mouse1_lib2.final_cell_0008',\n",
       " 'mouse1_lib2.final_cell_0009',\n",
       " 'mouse1_lib2.final_cell_0011',\n",
       " 'mouse1_lib2.final_cell_0012',\n",
       " 'mouse1_lib2.final_cell_0013',\n",
       " 'mouse1_lib2.final_cell_0014',\n",
       " 'mouse1_lib2.final_cell_0015',\n",
       " 'mouse1_lib2.final_cell_0016',\n",
       " 'mouse1_lib2.final_cell_0017',\n",
       " 'mouse1_lib2.final_cell_0018',\n",
       " 'mouse1_lib2.final_cell_0019',\n",
       " 'mouse1_lib2.final_cell_0020',\n",
       " 'mouse1_lib2.final_cell_0021',\n",
       " 'mouse1_lib2.final_cell_0022',\n",
       " 'mouse1_lib2.final_cell_0023',\n",
       " 'mouse1_lib2.final_cell_0024',\n",
       " 'mouse1_lib2.final_cell_0025',\n",
       " 'mouse1_lib2.final_cell_0026',\n",
       " 'mouse1_lib2.final_cell_0027',\n",
       " 'mouse1_lib2.final_cell_0028',\n",
       " 'mouse1_lib2.final_cell_0029',\n",
       " 'mouse1_lib2.final_cell_0030',\n",
       " 'mouse1_lib2.final_cell_0031',\n",
       " 'mouse1_lib2.final_cell_0032',\n",
       " 'mouse1_lib2.final_cell_0033',\n",
       " 'mouse1_lib2.final_cell_0034',\n",
       " 'mouse1_lib2.final_cell_0035',\n",
       " 'mouse1_lib2.final_cell_0036',\n",
       " 'mouse1_lib2.final_cell_0037',\n",
       " 'mouse1_lib2.final_cell_0038',\n",
       " 'mouse1_lib2.final_cell_0039',\n",
       " 'mouse1_lib2.final_cell_0040',\n",
       " 'mouse1_lib2.final_cell_0041',\n",
       " 'mouse1_lib2.final_cell_0042',\n",
       " 'mouse1_lib2.final_cell_0043',\n",
       " 'mouse1_lib2.final_cell_0044',\n",
       " 'mouse1_lib2.final_cell_0045',\n",
       " 'mouse1_lib2.final_cell_0046',\n",
       " 'mouse1_lib2.final_cell_0047',\n",
       " 'mouse1_lib2.final_cell_0048',\n",
       " 'mouse1_lib2.final_cell_0049',\n",
       " 'mouse1_lib2.final_cell_0050',\n",
       " 'mouse1_lib2.final_cell_0051',\n",
       " 'mouse1_lib2.final_cell_0052',\n",
       " 'mouse1_lib2.final_cell_0053',\n",
       " 'mouse1_lib2.final_cell_0054',\n",
       " 'mouse1_lib2.final_cell_0055',\n",
       " 'mouse1_lib2.final_cell_0056',\n",
       " 'mouse1_lib2.final_cell_0058',\n",
       " 'mouse1_lib2.final_cell_0059',\n",
       " 'mouse1_lib2.final_cell_0060',\n",
       " 'mouse1_lib2.final_cell_0061',\n",
       " 'mouse1_lib2.final_cell_0062',\n",
       " 'mouse1_lib2.final_cell_0063',\n",
       " 'mouse1_lib2.final_cell_0064',\n",
       " 'mouse1_lib2.final_cell_0065',\n",
       " 'mouse1_lib2.final_cell_0066',\n",
       " 'mouse1_lib2.final_cell_0067',\n",
       " 'mouse1_lib2.final_cell_0068',\n",
       " 'mouse1_lib2.final_cell_0069',\n",
       " 'mouse1_lib2.final_cell_0070',\n",
       " 'mouse1_lib2.final_cell_0071',\n",
       " 'mouse1_lib2.final_cell_0072',\n",
       " 'mouse1_lib2.final_cell_0073',\n",
       " 'mouse1_lib2.final_cell_0074',\n",
       " 'mouse1_lib2.final_cell_0075',\n",
       " 'mouse1_lib2.final_cell_0076',\n",
       " 'mouse1_lib2.final_cell_0077',\n",
       " 'mouse1_lib2.final_cell_0078',\n",
       " 'mouse1_lib2.final_cell_0079',\n",
       " 'mouse1_lib2.final_cell_0080',\n",
       " 'mouse1_lib2.final_cell_0081',\n",
       " 'mouse1_lib2.final_cell_0082',\n",
       " 'mouse1_lib2.final_cell_0083',\n",
       " 'mouse1_lib2.final_cell_0084',\n",
       " 'mouse1_lib2.final_cell_0085',\n",
       " 'mouse1_lib2.final_cell_0086',\n",
       " 'mouse1_lib2.final_cell_0087',\n",
       " 'mouse1_lib2.final_cell_0088',\n",
       " 'mouse1_lib2.final_cell_0089',\n",
       " 'mouse1_lib2.final_cell_0090',\n",
       " 'mouse1_lib2.final_cell_0091',\n",
       " 'mouse1_lib2.final_cell_0092',\n",
       " 'mouse1_lib2.final_cell_0093',\n",
       " 'mouse1_lib2.final_cell_0094',\n",
       " 'mouse1_lib2.final_cell_0095',\n",
       " 'mouse1_lib2.final_cell_0096',\n",
       " 'mouse1_lib2.final_cell_0097',\n",
       " 'mouse1_lib2.final_cell_0098',\n",
       " 'mouse1_lib2.final_cell_0099',\n",
       " 'mouse1_lib2.final_cell_0100',\n",
       " 'mouse1_lib2.final_cell_0101',\n",
       " 'mouse1_lib2.final_cell_0102',\n",
       " 'mouse1_lib2.final_cell_0103',\n",
       " 'mouse1_lib2.final_cell_0104',\n",
       " 'mouse1_lib2.final_cell_0105',\n",
       " 'mouse1_lib2.final_cell_0106',\n",
       " 'mouse1_lib2.final_cell_0107',\n",
       " 'mouse1_lib2.final_cell_0108',\n",
       " 'mouse1_lib2.final_cell_0109',\n",
       " 'mouse1_lib2.final_cell_0110',\n",
       " 'mouse1_lib2.final_cell_0111',\n",
       " 'mouse1_lib2.final_cell_0112',\n",
       " 'mouse1_lib2.final_cell_0113',\n",
       " 'mouse1_lib2.final_cell_0114',\n",
       " 'mouse1_lib2.final_cell_0115',\n",
       " 'mouse1_lib2.final_cell_0116',\n",
       " 'mouse1_lib2.final_cell_0117',\n",
       " 'mouse1_lib2.final_cell_0118',\n",
       " 'mouse1_lib2.final_cell_0119',\n",
       " 'mouse1_lib2.final_cell_0120',\n",
       " 'mouse1_lib2.final_cell_0121',\n",
       " 'mouse1_lib2.final_cell_0122',\n",
       " 'mouse1_lib2.final_cell_0123',\n",
       " 'mouse1_lib2.final_cell_0124',\n",
       " 'mouse1_lib2.final_cell_0125',\n",
       " 'mouse1_lib2.final_cell_0126',\n",
       " 'mouse1_lib2.final_cell_0127',\n",
       " 'mouse1_lib2.final_cell_0128',\n",
       " 'mouse1_lib2.final_cell_0129',\n",
       " 'mouse1_lib2.final_cell_0130',\n",
       " 'mouse1_lib2.final_cell_0131',\n",
       " 'mouse1_lib2.final_cell_0132',\n",
       " 'mouse1_lib2.final_cell_0133',\n",
       " 'mouse1_lib2.final_cell_0134',\n",
       " 'mouse1_lib2.final_cell_0135',\n",
       " 'mouse1_lib2.final_cell_0136',\n",
       " 'mouse1_lib2.final_cell_0137',\n",
       " 'mouse1_lib2.final_cell_0138',\n",
       " 'mouse1_lib2.final_cell_0139',\n",
       " 'mouse1_lib2.final_cell_0140',\n",
       " 'mouse1_lib2.final_cell_0141',\n",
       " 'mouse1_lib2.final_cell_0142',\n",
       " 'mouse1_lib2.final_cell_0143',\n",
       " 'mouse1_lib2.final_cell_0144',\n",
       " 'mouse1_lib2.final_cell_0145',\n",
       " 'mouse1_lib2.final_cell_0146',\n",
       " 'mouse1_lib2.final_cell_0147',\n",
       " 'mouse1_lib2.final_cell_0148',\n",
       " 'mouse1_lib2.final_cell_0149',\n",
       " 'mouse1_lib2.final_cell_0150',\n",
       " 'mouse1_lib2.final_cell_0151',\n",
       " 'mouse1_lib2.final_cell_0152',\n",
       " 'mouse1_lib2.final_cell_0153',\n",
       " 'mouse1_lib2.final_cell_0154',\n",
       " 'mouse1_lib2.final_cell_0155',\n",
       " 'mouse1_lib2.final_cell_0156',\n",
       " 'mouse1_lib2.final_cell_0157',\n",
       " 'mouse1_lib2.final_cell_0158',\n",
       " 'mouse1_lib2.final_cell_0159',\n",
       " 'mouse1_lib2.final_cell_0160',\n",
       " 'mouse1_lib2.final_cell_0161',\n",
       " 'mouse1_lib2.final_cell_0162',\n",
       " 'mouse1_lib2.final_cell_0163',\n",
       " 'mouse1_lib2.final_cell_0164',\n",
       " 'mouse1_lib2.final_cell_0165',\n",
       " 'mouse1_lib2.final_cell_0166',\n",
       " 'mouse1_lib2.final_cell_0167',\n",
       " 'mouse1_lib2.final_cell_0168',\n",
       " 'mouse1_lib2.final_cell_0169',\n",
       " 'mouse1_lib2.final_cell_0170',\n",
       " 'mouse1_lib2.final_cell_0171',\n",
       " 'mouse1_lib2.final_cell_0172',\n",
       " 'mouse1_lib2.final_cell_0173',\n",
       " 'mouse1_lib2.final_cell_0174',\n",
       " 'mouse1_lib2.final_cell_0175',\n",
       " 'mouse1_lib2.final_cell_0176',\n",
       " 'mouse1_lib2.final_cell_0177',\n",
       " 'mouse1_lib2.final_cell_0178',\n",
       " 'mouse1_lib2.final_cell_0179',\n",
       " 'mouse1_lib2.final_cell_0180',\n",
       " 'mouse1_lib2.final_cell_0181',\n",
       " 'mouse1_lib2.final_cell_0182',\n",
       " 'mouse1_lib2.final_cell_0183',\n",
       " 'mouse1_lib2.final_cell_0184',\n",
       " 'mouse1_lib2.final_cell_0185',\n",
       " 'mouse1_lib2.final_cell_0186',\n",
       " 'mouse1_lib2.final_cell_0187',\n",
       " 'mouse1_lib2.final_cell_0188',\n",
       " 'mouse1_lib2.final_cell_0189',\n",
       " 'mouse1_lib2.final_cell_0190',\n",
       " 'mouse1_lib2.final_cell_0191',\n",
       " 'mouse1_lib2.final_cell_0192',\n",
       " 'mouse1_lib2.final_cell_0193',\n",
       " 'mouse1_lib2.final_cell_0194',\n",
       " 'mouse1_lib2.final_cell_0195',\n",
       " 'mouse1_lib2.final_cell_0196',\n",
       " 'mouse1_lib2.final_cell_0197',\n",
       " 'mouse1_lib2.final_cell_0198',\n",
       " 'mouse1_lib2.final_cell_0199',\n",
       " 'mouse1_lib2.final_cell_0200',\n",
       " 'mouse1_lib2.final_cell_0201',\n",
       " 'mouse1_lib2.final_cell_0202',\n",
       " 'mouse1_lib2.final_cell_0203',\n",
       " 'mouse1_lib2.final_cell_0204',\n",
       " 'mouse1_lib2.final_cell_0205',\n",
       " 'mouse1_lib2.final_cell_0206',\n",
       " 'mouse1_lib2.final_cell_0207',\n",
       " 'mouse1_lib2.final_cell_0208',\n",
       " 'mouse1_lib2.final_cell_0209',\n",
       " 'mouse1_lib2.final_cell_0210',\n",
       " 'mouse1_lib2.final_cell_0211',\n",
       " 'mouse1_lib2.final_cell_0212',\n",
       " 'mouse1_lib2.final_cell_0213',\n",
       " 'mouse1_lib2.final_cell_0214',\n",
       " 'mouse1_lib2.final_cell_0215',\n",
       " 'mouse1_lib2.final_cell_0216',\n",
       " 'mouse1_lib2.final_cell_0217',\n",
       " 'mouse1_lib2.final_cell_0218',\n",
       " 'mouse1_lib2.final_cell_0219',\n",
       " 'mouse1_lib2.final_cell_0220',\n",
       " 'mouse1_lib2.final_cell_0221',\n",
       " 'mouse1_lib2.final_cell_0222',\n",
       " 'mouse1_lib2.final_cell_0223',\n",
       " 'mouse1_lib2.final_cell_0224',\n",
       " 'mouse1_lib2.final_cell_0225',\n",
       " 'mouse1_lib2.final_cell_0226',\n",
       " 'mouse1_lib2.final_cell_0227',\n",
       " 'mouse1_lib2.final_cell_0228',\n",
       " 'mouse1_lib2.final_cell_0229',\n",
       " 'mouse1_lib2.final_cell_0230',\n",
       " 'mouse1_lib2.final_cell_0231',\n",
       " 'mouse1_lib2.final_cell_0232',\n",
       " 'mouse1_lib2.final_cell_0233',\n",
       " 'mouse1_lib2.final_cell_0234',\n",
       " 'mouse1_lib2.final_cell_0235',\n",
       " 'mouse1_lib2.final_cell_0236',\n",
       " 'mouse1_lib2.final_cell_0237',\n",
       " 'mouse1_lib2.final_cell_0238',\n",
       " 'mouse1_lib2.final_cell_0239',\n",
       " 'mouse1_lib2.final_cell_0240',\n",
       " 'mouse1_lib2.final_cell_0241',\n",
       " 'mouse1_lib2.final_cell_0242',\n",
       " 'mouse1_lib2.final_cell_0243',\n",
       " 'mouse1_lib2.final_cell_0244',\n",
       " 'mouse1_lib2.final_cell_0245',\n",
       " 'mouse1_lib2.final_cell_0246',\n",
       " 'mouse1_lib2.final_cell_0247',\n",
       " 'mouse1_lib2.final_cell_0248',\n",
       " 'mouse1_lib2.final_cell_0249',\n",
       " 'mouse1_lib2.final_cell_0250',\n",
       " 'mouse1_lib2.final_cell_0251',\n",
       " 'mouse1_lib2.final_cell_0252',\n",
       " 'mouse1_lib2.final_cell_0253',\n",
       " 'mouse1_lib2.final_cell_0254',\n",
       " 'mouse1_lib2.final_cell_0255',\n",
       " 'mouse1_lib2.final_cell_0256',\n",
       " 'mouse1_lib2.final_cell_0257',\n",
       " 'mouse1_lib2.final_cell_0258',\n",
       " 'mouse1_lib2.final_cell_0259',\n",
       " 'mouse1_lib2.final_cell_0260',\n",
       " 'mouse1_lib2.final_cell_0261',\n",
       " 'mouse1_lib2.final_cell_0262',\n",
       " 'mouse1_lib2.final_cell_0263',\n",
       " 'mouse1_lib2.final_cell_0264',\n",
       " 'mouse1_lib2.final_cell_0265',\n",
       " 'mouse1_lib2.final_cell_0266',\n",
       " 'mouse1_lib2.final_cell_0267',\n",
       " 'mouse1_lib2.final_cell_0268',\n",
       " 'mouse1_lib2.final_cell_0270',\n",
       " 'mouse1_lib2.final_cell_0271',\n",
       " 'mouse1_lib2.final_cell_0272',\n",
       " 'mouse1_lib2.final_cell_0273',\n",
       " 'mouse1_lib2.final_cell_0274',\n",
       " 'mouse1_lib2.final_cell_0275',\n",
       " 'mouse1_lib2.final_cell_0276',\n",
       " 'mouse1_lib2.final_cell_0277',\n",
       " 'mouse1_lib2.final_cell_0278',\n",
       " 'mouse1_lib2.final_cell_0279',\n",
       " 'mouse1_lib2.final_cell_0280',\n",
       " 'mouse1_lib2.final_cell_0281',\n",
       " 'mouse1_lib2.final_cell_0282',\n",
       " 'mouse1_lib2.final_cell_0283',\n",
       " 'mouse1_lib2.final_cell_0284',\n",
       " 'mouse1_lib2.final_cell_0285',\n",
       " 'mouse1_lib2.final_cell_0286',\n",
       " 'mouse1_lib2.final_cell_0287',\n",
       " 'mouse1_lib2.final_cell_0288',\n",
       " 'mouse1_lib2.final_cell_0289',\n",
       " 'mouse1_lib2.final_cell_0290',\n",
       " 'mouse1_lib2.final_cell_0291',\n",
       " 'mouse1_lib3.final_cell_0001',\n",
       " 'mouse1_lib3.final_cell_0002',\n",
       " 'mouse1_lib3.final_cell_0003',\n",
       " 'mouse1_lib3.final_cell_0004',\n",
       " 'mouse1_lib3.final_cell_0005',\n",
       " 'mouse1_lib3.final_cell_0006',\n",
       " 'mouse1_lib3.final_cell_0007',\n",
       " 'mouse1_lib3.final_cell_0008',\n",
       " 'mouse1_lib3.final_cell_0009',\n",
       " 'mouse1_lib3.final_cell_0010',\n",
       " 'mouse1_lib3.final_cell_0011',\n",
       " 'mouse1_lib3.final_cell_0012',\n",
       " 'mouse1_lib3.final_cell_0013',\n",
       " 'mouse1_lib3.final_cell_0014',\n",
       " 'mouse1_lib3.final_cell_0015',\n",
       " 'mouse1_lib3.final_cell_0016',\n",
       " 'mouse1_lib3.final_cell_0017',\n",
       " 'mouse1_lib3.final_cell_0018',\n",
       " 'mouse1_lib3.final_cell_0019',\n",
       " 'mouse1_lib3.final_cell_0020',\n",
       " 'mouse1_lib3.final_cell_0021',\n",
       " 'mouse1_lib3.final_cell_0022',\n",
       " 'mouse1_lib3.final_cell_0023',\n",
       " 'mouse1_lib3.final_cell_0024',\n",
       " 'mouse1_lib3.final_cell_0025',\n",
       " 'mouse1_lib3.final_cell_0026',\n",
       " 'mouse1_lib3.final_cell_0027',\n",
       " 'mouse1_lib3.final_cell_0028',\n",
       " 'mouse1_lib3.final_cell_0029',\n",
       " 'mouse1_lib3.final_cell_0030',\n",
       " 'mouse1_lib3.final_cell_0031',\n",
       " 'mouse1_lib3.final_cell_0032',\n",
       " 'mouse1_lib3.final_cell_0033',\n",
       " 'mouse1_lib3.final_cell_0034',\n",
       " 'mouse1_lib3.final_cell_0035',\n",
       " 'mouse1_lib3.final_cell_0036',\n",
       " 'mouse1_lib3.final_cell_0037',\n",
       " 'mouse1_lib3.final_cell_0038',\n",
       " 'mouse1_lib3.final_cell_0039',\n",
       " 'mouse1_lib3.final_cell_0040',\n",
       " 'mouse1_lib3.final_cell_0041',\n",
       " 'mouse1_lib3.final_cell_0042',\n",
       " 'mouse1_lib3.final_cell_0043',\n",
       " 'mouse1_lib3.final_cell_0044',\n",
       " 'mouse1_lib3.final_cell_0045',\n",
       " 'mouse1_lib3.final_cell_0046',\n",
       " 'mouse1_lib3.final_cell_0047',\n",
       " 'mouse1_lib3.final_cell_0048',\n",
       " 'mouse1_lib3.final_cell_0049',\n",
       " 'mouse1_lib3.final_cell_0050',\n",
       " 'mouse1_lib3.final_cell_0051',\n",
       " 'mouse1_lib3.final_cell_0052',\n",
       " 'mouse1_lib3.final_cell_0053',\n",
       " 'mouse1_lib3.final_cell_0054',\n",
       " 'mouse1_lib3.final_cell_0055',\n",
       " 'mouse1_lib3.final_cell_0056',\n",
       " 'mouse1_lib3.final_cell_0057',\n",
       " 'mouse1_lib3.final_cell_0058',\n",
       " 'mouse1_lib3.final_cell_0059',\n",
       " 'mouse1_lib3.final_cell_0060',\n",
       " 'mouse1_lib3.final_cell_0061',\n",
       " 'mouse1_lib3.final_cell_0062',\n",
       " 'mouse1_lib3.final_cell_0063',\n",
       " 'mouse1_lib3.final_cell_0064',\n",
       " 'mouse1_lib3.final_cell_0065',\n",
       " 'mouse1_lib3.final_cell_0066',\n",
       " 'mouse1_lib3.final_cell_0067',\n",
       " 'mouse1_lib3.final_cell_0068',\n",
       " 'mouse1_lib3.final_cell_0069',\n",
       " 'mouse1_lib3.final_cell_0070',\n",
       " 'mouse1_lib3.final_cell_0071',\n",
       " 'mouse1_lib3.final_cell_0072',\n",
       " 'mouse1_lib3.final_cell_0073',\n",
       " 'mouse1_lib3.final_cell_0074',\n",
       " 'mouse1_lib3.final_cell_0075',\n",
       " 'mouse1_lib3.final_cell_0076',\n",
       " 'mouse1_lib3.final_cell_0077',\n",
       " 'mouse1_lib3.final_cell_0080',\n",
       " 'mouse1_lib3.final_cell_0081',\n",
       " 'mouse1_lib3.final_cell_0082',\n",
       " 'mouse1_lib3.final_cell_0083',\n",
       " 'mouse1_lib3.final_cell_0084',\n",
       " 'mouse1_lib3.final_cell_0085',\n",
       " 'mouse1_lib3.final_cell_0086',\n",
       " 'mouse1_lib3.final_cell_0087',\n",
       " 'mouse1_lib3.final_cell_0088',\n",
       " 'mouse1_lib3.final_cell_0089',\n",
       " 'mouse1_lib3.final_cell_0090',\n",
       " 'mouse1_lib3.final_cell_0091',\n",
       " 'mouse1_lib3.final_cell_0092',\n",
       " 'mouse1_lib3.final_cell_0093',\n",
       " 'mouse1_lib3.final_cell_0094',\n",
       " 'mouse1_lib3.final_cell_0095',\n",
       " 'mouse1_lib3.final_cell_0096',\n",
       " 'mouse1_lib3.final_cell_0097',\n",
       " 'mouse1_lib3.final_cell_0098',\n",
       " 'mouse1_lib3.final_cell_0099',\n",
       " 'mouse1_lib3.final_cell_0100',\n",
       " 'mouse1_lib3.final_cell_0101',\n",
       " 'mouse1_lib3.final_cell_0102',\n",
       " 'mouse1_lib3.final_cell_0103',\n",
       " 'mouse1_lib3.final_cell_0104',\n",
       " 'mouse1_lib3.final_cell_0105',\n",
       " 'mouse1_lib3.final_cell_0106',\n",
       " 'mouse1_lib3.final_cell_0107',\n",
       " 'mouse1_lib3.final_cell_0108',\n",
       " 'mouse1_lib3.final_cell_0110',\n",
       " 'mouse1_lib3.final_cell_0111',\n",
       " 'mouse1_lib3.final_cell_0112',\n",
       " 'mouse1_lib3.final_cell_0113',\n",
       " 'mouse1_lib3.final_cell_0114',\n",
       " 'mouse1_lib3.final_cell_0115',\n",
       " 'mouse1_lib3.final_cell_0116',\n",
       " 'mouse1_lib3.final_cell_0117',\n",
       " 'mouse1_lib3.final_cell_0118',\n",
       " 'mouse1_lib3.final_cell_0119',\n",
       " 'mouse1_lib3.final_cell_0120',\n",
       " 'mouse1_lib3.final_cell_0121',\n",
       " 'mouse1_lib3.final_cell_0122',\n",
       " 'mouse1_lib3.final_cell_0123',\n",
       " 'mouse1_lib3.final_cell_0124',\n",
       " 'mouse1_lib3.final_cell_0125',\n",
       " 'mouse1_lib3.final_cell_0126',\n",
       " 'mouse1_lib3.final_cell_0127',\n",
       " 'mouse1_lib3.final_cell_0128',\n",
       " 'mouse1_lib3.final_cell_0129',\n",
       " 'mouse1_lib3.final_cell_0130',\n",
       " 'mouse1_lib3.final_cell_0131',\n",
       " 'mouse1_lib3.final_cell_0132',\n",
       " 'mouse1_lib3.final_cell_0133',\n",
       " 'mouse1_lib3.final_cell_0134',\n",
       " 'mouse1_lib3.final_cell_0135',\n",
       " 'mouse1_lib3.final_cell_0136',\n",
       " 'mouse1_lib3.final_cell_0137',\n",
       " 'mouse1_lib3.final_cell_0138',\n",
       " 'mouse1_lib3.final_cell_0139',\n",
       " 'mouse1_lib3.final_cell_0140',\n",
       " 'mouse1_lib3.final_cell_0141',\n",
       " 'mouse1_lib3.final_cell_0142',\n",
       " 'mouse1_lib3.final_cell_0143',\n",
       " 'mouse1_lib3.final_cell_0144',\n",
       " 'mouse1_lib3.final_cell_0145',\n",
       " 'mouse1_lib3.final_cell_0146',\n",
       " 'mouse1_lib3.final_cell_0147',\n",
       " 'mouse1_lib3.final_cell_0148',\n",
       " 'mouse1_lib3.final_cell_0149',\n",
       " 'mouse1_lib3.final_cell_0150',\n",
       " 'mouse1_lib3.final_cell_0151',\n",
       " 'mouse1_lib3.final_cell_0152',\n",
       " 'mouse1_lib3.final_cell_0153',\n",
       " 'mouse1_lib3.final_cell_0154',\n",
       " 'mouse1_lib3.final_cell_0155',\n",
       " 'mouse1_lib3.final_cell_0156',\n",
       " 'mouse1_lib3.final_cell_0157',\n",
       " 'mouse1_lib3.final_cell_0158',\n",
       " 'mouse1_lib3.final_cell_0159',\n",
       " 'mouse1_lib3.final_cell_0160',\n",
       " 'mouse1_lib3.final_cell_0161',\n",
       " 'mouse1_lib3.final_cell_0162',\n",
       " 'mouse1_lib3.final_cell_0163',\n",
       " 'mouse1_lib3.final_cell_0164',\n",
       " 'mouse1_lib3.final_cell_0165',\n",
       " 'mouse1_lib3.final_cell_0166',\n",
       " 'mouse1_lib3.final_cell_0167',\n",
       " 'mouse1_lib3.final_cell_0168',\n",
       " 'mouse1_lib3.final_cell_0169',\n",
       " 'mouse1_lib3.final_cell_0170',\n",
       " 'mouse1_lib3.final_cell_0171',\n",
       " 'mouse1_lib3.final_cell_0172',\n",
       " 'mouse1_lib3.final_cell_0173',\n",
       " 'mouse1_lib3.final_cell_0174',\n",
       " 'mouse1_lib3.final_cell_0175',\n",
       " 'mouse1_lib3.final_cell_0176',\n",
       " 'mouse1_lib3.final_cell_0177',\n",
       " 'mouse1_lib3.final_cell_0178',\n",
       " 'mouse1_lib3.final_cell_0179',\n",
       " 'mouse1_lib3.final_cell_0180',\n",
       " 'mouse1_lib3.final_cell_0181',\n",
       " 'mouse1_lib3.final_cell_0182',\n",
       " 'mouse1_lib3.final_cell_0183',\n",
       " 'mouse1_lib3.final_cell_0184',\n",
       " 'mouse1_lib3.final_cell_0185',\n",
       " 'mouse1_lib3.final_cell_0186',\n",
       " 'mouse1_lib3.final_cell_0187',\n",
       " 'mouse1_lib3.final_cell_0188',\n",
       " 'mouse1_lib3.final_cell_0189',\n",
       " 'mouse1_lib3.final_cell_0190',\n",
       " 'mouse1_lib3.final_cell_0191',\n",
       " 'mouse1_lib3.final_cell_0192',\n",
       " 'mouse1_lib3.final_cell_0193',\n",
       " 'mouse1_lib3.final_cell_0194',\n",
       " 'mouse1_lib3.final_cell_0195',\n",
       " 'mouse1_lib3.final_cell_0196',\n",
       " 'mouse1_lib3.final_cell_0197',\n",
       " 'mouse1_lib3.final_cell_0198',\n",
       " 'mouse1_lib3.final_cell_0199',\n",
       " 'mouse1_lib3.final_cell_0201',\n",
       " 'mouse1_lib3.final_cell_0202',\n",
       " 'mouse1_lib3.final_cell_0203',\n",
       " 'mouse1_lib3.final_cell_0204',\n",
       " 'mouse1_lib3.final_cell_0205',\n",
       " 'mouse1_lib3.final_cell_0206',\n",
       " 'mouse1_lib3.final_cell_0207',\n",
       " 'mouse1_lib3.final_cell_0208',\n",
       " 'mouse1_lib3.final_cell_0209',\n",
       " 'mouse1_lib3.final_cell_0210',\n",
       " 'mouse1_lib3.final_cell_0211',\n",
       " 'mouse1_lib3.final_cell_0212',\n",
       " 'mouse1_lib3.final_cell_0213',\n",
       " 'mouse1_lib3.final_cell_0214',\n",
       " 'mouse1_lib3.final_cell_0215',\n",
       " 'mouse1_lib3.final_cell_0217',\n",
       " 'mouse1_lib3.final_cell_0218',\n",
       " 'mouse1_lib3.final_cell_0219',\n",
       " 'mouse1_lib3.final_cell_0221',\n",
       " 'mouse1_lib3.final_cell_0222',\n",
       " 'mouse1_lib3.final_cell_0223',\n",
       " 'mouse1_lib3.final_cell_0224',\n",
       " 'mouse1_lib3.final_cell_0225',\n",
       " 'mouse1_lib3.final_cell_0226',\n",
       " 'mouse1_lib3.final_cell_0227',\n",
       " 'mouse1_lib3.final_cell_0228',\n",
       " 'mouse1_lib3.final_cell_0229',\n",
       " 'mouse1_lib3.final_cell_0231',\n",
       " 'mouse1_lib3.final_cell_0232',\n",
       " 'mouse1_lib3.final_cell_0233',\n",
       " 'mouse1_lib3.final_cell_0234',\n",
       " 'mouse1_lib3.final_cell_0235',\n",
       " 'mouse1_lib3.final_cell_0236',\n",
       " 'mouse1_lib3.final_cell_0237',\n",
       " 'mouse1_lib3.final_cell_0238',\n",
       " 'mouse1_lib3.final_cell_0239',\n",
       " 'mouse1_lib3.final_cell_0240',\n",
       " 'mouse1_lib3.final_cell_0241',\n",
       " 'mouse1_lib3.final_cell_0242',\n",
       " 'mouse1_lib3.final_cell_0243',\n",
       " 'mouse1_lib3.final_cell_0244',\n",
       " 'mouse1_lib3.final_cell_0245',\n",
       " 'mouse1_lib3.final_cell_0246',\n",
       " 'mouse1_lib3.final_cell_0247',\n",
       " 'mouse1_lib3.final_cell_0248',\n",
       " 'mouse1_lib3.final_cell_0249',\n",
       " 'mouse1_lib3.final_cell_0251',\n",
       " 'mouse1_lib3.final_cell_0252',\n",
       " 'mouse1_lib3.final_cell_0253',\n",
       " 'mouse1_lib3.final_cell_0254',\n",
       " 'mouse2_lib1.final_cell_0001',\n",
       " 'mouse2_lib1.final_cell_0002',\n",
       " 'mouse2_lib1.final_cell_0003',\n",
       " 'mouse2_lib1.final_cell_0004',\n",
       " 'mouse2_lib1.final_cell_0005',\n",
       " 'mouse2_lib1.final_cell_0006',\n",
       " 'mouse2_lib1.final_cell_0007',\n",
       " 'mouse2_lib1.final_cell_0008',\n",
       " 'mouse2_lib1.final_cell_0009',\n",
       " 'mouse2_lib1.final_cell_0010',\n",
       " 'mouse2_lib1.final_cell_0011',\n",
       " 'mouse2_lib1.final_cell_0012',\n",
       " 'mouse2_lib1.final_cell_0013',\n",
       " 'mouse2_lib1.final_cell_0014',\n",
       " 'mouse2_lib1.final_cell_0015',\n",
       " 'mouse2_lib1.final_cell_0016',\n",
       " 'mouse2_lib1.final_cell_0017',\n",
       " 'mouse2_lib1.final_cell_0018',\n",
       " 'mouse2_lib1.final_cell_0019',\n",
       " 'mouse2_lib1.final_cell_0020',\n",
       " 'mouse2_lib1.final_cell_0021',\n",
       " 'mouse2_lib1.final_cell_0022',\n",
       " 'mouse2_lib1.final_cell_0023',\n",
       " 'mouse2_lib1.final_cell_0024',\n",
       " 'mouse2_lib1.final_cell_0025',\n",
       " 'mouse2_lib1.final_cell_0026',\n",
       " 'mouse2_lib1.final_cell_0027',\n",
       " 'mouse2_lib1.final_cell_0028',\n",
       " 'mouse2_lib1.final_cell_0029',\n",
       " 'mouse2_lib1.final_cell_0030',\n",
       " 'mouse2_lib1.final_cell_0031',\n",
       " 'mouse2_lib1.final_cell_0032',\n",
       " 'mouse2_lib1.final_cell_0033',\n",
       " 'mouse2_lib1.final_cell_0034',\n",
       " 'mouse2_lib1.final_cell_0035',\n",
       " 'mouse2_lib1.final_cell_0036',\n",
       " 'mouse2_lib1.final_cell_0037',\n",
       " 'mouse2_lib1.final_cell_0038',\n",
       " 'mouse2_lib1.final_cell_0039',\n",
       " 'mouse2_lib1.final_cell_0040',\n",
       " 'mouse2_lib1.final_cell_0041',\n",
       " 'mouse2_lib1.final_cell_0042',\n",
       " 'mouse2_lib1.final_cell_0043',\n",
       " 'mouse2_lib1.final_cell_0044',\n",
       " 'mouse2_lib1.final_cell_0045',\n",
       " 'mouse2_lib1.final_cell_0046',\n",
       " 'mouse2_lib1.final_cell_0047',\n",
       " 'mouse2_lib1.final_cell_0048',\n",
       " 'mouse2_lib1.final_cell_0049',\n",
       " 'mouse2_lib1.final_cell_0050',\n",
       " 'mouse2_lib1.final_cell_0051',\n",
       " 'mouse2_lib1.final_cell_0052',\n",
       " 'mouse2_lib1.final_cell_0053',\n",
       " 'mouse2_lib1.final_cell_0054',\n",
       " 'mouse2_lib1.final_cell_0055',\n",
       " 'mouse2_lib1.final_cell_0056',\n",
       " 'mouse2_lib1.final_cell_0057',\n",
       " 'mouse2_lib1.final_cell_0058',\n",
       " 'mouse2_lib1.final_cell_0059',\n",
       " 'mouse2_lib1.final_cell_0060',\n",
       " 'mouse2_lib1.final_cell_0061',\n",
       " 'mouse2_lib1.final_cell_0062',\n",
       " 'mouse2_lib1.final_cell_0063',\n",
       " 'mouse2_lib1.final_cell_0064',\n",
       " 'mouse2_lib1.final_cell_0065',\n",
       " 'mouse2_lib1.final_cell_0066',\n",
       " 'mouse2_lib1.final_cell_0067',\n",
       " 'mouse2_lib1.final_cell_0068',\n",
       " 'mouse2_lib1.final_cell_0069',\n",
       " 'mouse2_lib1.final_cell_0070',\n",
       " 'mouse2_lib1.final_cell_0071',\n",
       " 'mouse2_lib1.final_cell_0072',\n",
       " 'mouse2_lib1.final_cell_0073',\n",
       " 'mouse2_lib1.final_cell_0074',\n",
       " 'mouse2_lib1.final_cell_0075',\n",
       " 'mouse2_lib1.final_cell_0076',\n",
       " 'mouse2_lib1.final_cell_0077',\n",
       " 'mouse2_lib1.final_cell_0078',\n",
       " 'mouse2_lib1.final_cell_0079',\n",
       " 'mouse2_lib1.final_cell_0080',\n",
       " 'mouse2_lib1.final_cell_0081',\n",
       " 'mouse2_lib1.final_cell_0082',\n",
       " 'mouse2_lib1.final_cell_0084',\n",
       " 'mouse2_lib1.final_cell_0085',\n",
       " 'mouse2_lib1.final_cell_0086',\n",
       " 'mouse2_lib1.final_cell_0087',\n",
       " 'mouse2_lib1.final_cell_0088',\n",
       " 'mouse2_lib1.final_cell_0089',\n",
       " 'mouse2_lib1.final_cell_0090',\n",
       " 'mouse2_lib1.final_cell_0091',\n",
       " 'mouse2_lib1.final_cell_0092',\n",
       " 'mouse2_lib1.final_cell_0093',\n",
       " 'mouse2_lib1.final_cell_0094',\n",
       " 'mouse2_lib1.final_cell_0095',\n",
       " 'mouse2_lib1.final_cell_0096',\n",
       " 'mouse2_lib1.final_cell_0097',\n",
       " 'mouse2_lib1.final_cell_0098',\n",
       " 'mouse2_lib1.final_cell_0099',\n",
       " 'mouse2_lib1.final_cell_0100',\n",
       " 'mouse2_lib1.final_cell_0101',\n",
       " 'mouse2_lib1.final_cell_0102',\n",
       " 'mouse2_lib1.final_cell_0103',\n",
       " 'mouse2_lib1.final_cell_0104',\n",
       " 'mouse2_lib1.final_cell_0105',\n",
       " 'mouse2_lib1.final_cell_0106',\n",
       " 'mouse2_lib1.final_cell_0107',\n",
       " 'mouse2_lib1.final_cell_0108',\n",
       " 'mouse2_lib1.final_cell_0109',\n",
       " 'mouse2_lib1.final_cell_0110',\n",
       " 'mouse2_lib1.final_cell_0111',\n",
       " 'mouse2_lib1.final_cell_0112',\n",
       " 'mouse2_lib1.final_cell_0113',\n",
       " 'mouse2_lib1.final_cell_0114',\n",
       " 'mouse2_lib1.final_cell_0115',\n",
       " 'mouse2_lib1.final_cell_0116',\n",
       " 'mouse2_lib1.final_cell_0117',\n",
       " 'mouse2_lib1.final_cell_0118',\n",
       " 'mouse2_lib1.final_cell_0119',\n",
       " 'mouse2_lib1.final_cell_0120',\n",
       " 'mouse2_lib1.final_cell_0121',\n",
       " 'mouse2_lib1.final_cell_0122',\n",
       " 'mouse2_lib1.final_cell_0123',\n",
       " 'mouse2_lib1.final_cell_0124',\n",
       " 'mouse2_lib1.final_cell_0125',\n",
       " 'mouse2_lib1.final_cell_0126',\n",
       " 'mouse2_lib1.final_cell_0127',\n",
       " 'mouse2_lib1.final_cell_0128',\n",
       " 'mouse2_lib1.final_cell_0129',\n",
       " 'mouse2_lib1.final_cell_0130',\n",
       " 'mouse2_lib1.final_cell_0131',\n",
       " 'mouse2_lib1.final_cell_0132',\n",
       " 'mouse2_lib1.final_cell_0133',\n",
       " 'mouse2_lib1.final_cell_0134',\n",
       " 'mouse2_lib1.final_cell_0135',\n",
       " 'mouse2_lib1.final_cell_0136',\n",
       " 'mouse2_lib1.final_cell_0137',\n",
       " 'mouse2_lib1.final_cell_0138',\n",
       " 'mouse2_lib1.final_cell_0139',\n",
       " 'mouse2_lib1.final_cell_0140',\n",
       " 'mouse2_lib1.final_cell_0141',\n",
       " 'mouse2_lib1.final_cell_0142',\n",
       " 'mouse2_lib1.final_cell_0143',\n",
       " 'mouse2_lib1.final_cell_0144',\n",
       " 'mouse2_lib1.final_cell_0145',\n",
       " 'mouse2_lib1.final_cell_0146',\n",
       " 'mouse2_lib1.final_cell_0147',\n",
       " 'mouse2_lib1.final_cell_0148',\n",
       " 'mouse2_lib1.final_cell_0149',\n",
       " 'mouse2_lib1.final_cell_0150',\n",
       " 'mouse2_lib1.final_cell_0151',\n",
       " 'mouse2_lib1.final_cell_0152',\n",
       " 'mouse2_lib1.final_cell_0153',\n",
       " 'mouse2_lib1.final_cell_0154',\n",
       " 'mouse2_lib1.final_cell_0155',\n",
       " 'mouse2_lib1.final_cell_0156',\n",
       " 'mouse2_lib1.final_cell_0157',\n",
       " 'mouse2_lib1.final_cell_0158',\n",
       " 'mouse2_lib1.final_cell_0159',\n",
       " 'mouse2_lib1.final_cell_0160',\n",
       " 'mouse2_lib1.final_cell_0161',\n",
       " 'mouse2_lib1.final_cell_0162',\n",
       " 'mouse2_lib1.final_cell_0163',\n",
       " 'mouse2_lib1.final_cell_0164',\n",
       " 'mouse2_lib1.final_cell_0165',\n",
       " 'mouse2_lib1.final_cell_0166',\n",
       " 'mouse2_lib1.final_cell_0167',\n",
       " 'mouse2_lib1.final_cell_0168',\n",
       " 'mouse2_lib1.final_cell_0169',\n",
       " 'mouse2_lib1.final_cell_0170',\n",
       " 'mouse2_lib1.final_cell_0171',\n",
       " 'mouse2_lib1.final_cell_0172',\n",
       " 'mouse2_lib1.final_cell_0173',\n",
       " 'mouse2_lib1.final_cell_0174',\n",
       " 'mouse2_lib1.final_cell_0175',\n",
       " 'mouse2_lib1.final_cell_0176',\n",
       " 'mouse2_lib1.final_cell_0177',\n",
       " 'mouse2_lib1.final_cell_0178',\n",
       " 'mouse2_lib1.final_cell_0179',\n",
       " 'mouse2_lib1.final_cell_0180',\n",
       " 'mouse2_lib1.final_cell_0181',\n",
       " 'mouse2_lib1.final_cell_0182',\n",
       " 'mouse2_lib1.final_cell_0183',\n",
       " 'mouse2_lib1.final_cell_0184',\n",
       " 'mouse2_lib1.final_cell_0185',\n",
       " 'mouse2_lib1.final_cell_0186',\n",
       " 'mouse2_lib1.final_cell_0187',\n",
       " 'mouse2_lib1.final_cell_0188',\n",
       " 'mouse2_lib1.final_cell_0189',\n",
       " 'mouse2_lib1.final_cell_0190',\n",
       " 'mouse2_lib1.final_cell_0191',\n",
       " 'mouse2_lib1.final_cell_0192',\n",
       " 'mouse2_lib1.final_cell_0193',\n",
       " 'mouse2_lib1.final_cell_0194',\n",
       " 'mouse2_lib1.final_cell_0195',\n",
       " 'mouse2_lib1.final_cell_0196',\n",
       " ...]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c34d50fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "types = np.unique(lab_label2['type']).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01d45d06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alpha',\n",
       " 'beta',\n",
       " 'delta',\n",
       " 'ductal',\n",
       " 'endothelial',\n",
       " 'gamma',\n",
       " 'macrophage',\n",
       " 'quiescent_stellate']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "65ce732c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels = pd.DataFrame(np.array(lab_label2).flatten())\n",
    "true_label = Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70b0a180",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename = {}\n",
    "\n",
    "for line in range(0, len(types)):\n",
    "    key = types[line]\n",
    "    rename[key] = int(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10f224e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0,\n",
       " 'beta': 1,\n",
       " 'delta': 2,\n",
       " 'ductal': 3,\n",
       " 'endothelial': 4,\n",
       " 'gamma': 5,\n",
       " 'macrophage': 6,\n",
       " 'quiescent_stellate': 7}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9b1f0b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alpha',\n",
       " 'beta',\n",
       " 'delta',\n",
       " 'ductal',\n",
       " 'endothelial',\n",
       " 'gamma',\n",
       " 'macrophage',\n",
       " 'quiescent_stellate']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(rename.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0de6e7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Labels = Labels.replace({'duc': 'ductal'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5de32d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "Label1 = Labels.replace(rename)\n",
    "indices = np.array(Label1.values, dtype='int').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b61deef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "indice = [item for sublist in indices for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b3003652",
   "metadata": {},
   "outputs": [],
   "source": [
    "#' convert list to binary matrix\n",
    "indptr = range(len(indice) + 1)\n",
    "dat = np.ones(len(indice))\n",
    "binary_label = scipy.sparse.csr_matrix((dat, indice, indptr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "503659d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label = np.array(binary_label.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0ff4468c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e37dde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a5d69d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdef68c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def preprocess_features(features):\n",
    "    \"\"\"Row-normalize feature matrix and convert to tuple representation\"\"\"\n",
    "    rowsum = np.array(features.sum(1))\n",
    "    r_inv = np.power(rowsum, -1).flatten()\n",
    "    r_inv[np.isinf(r_inv)] = 0.\n",
    "    r_mat_inv = sp.diags(r_inv)\n",
    "    features = r_mat_inv.dot(features)\n",
    "    return sparse_to_tuple(features)\n",
    "\n",
    "def sparse_to_tuple(sparse_mx):\n",
    "    \"\"\"Convert sparse matrix to tuple representation.\"\"\"\n",
    "    def to_tuple(mx):\n",
    "        if not sp.isspmatrix_coo(mx):\n",
    "            mx = mx.tocoo()\n",
    "        coords = np.vstack((mx.row, mx.col)).transpose()\n",
    "        values = mx.data\n",
    "        shape = mx.shape\n",
    "        return coords, values, shape\n",
    "\n",
    "    if isinstance(sparse_mx, list):\n",
    "        for i in range(len(sparse_mx)):\n",
    "            sparse_mx[i] = to_tuple(sparse_mx[i])\n",
    "    else:\n",
    "        sparse_mx = to_tuple(sparse_mx)\n",
    "\n",
    "    return sparse_mx\n",
    "def graph(matrix):\n",
    "    adj = defaultdict(list)  # default value of int is 0\n",
    "    for i, row in enumerate(matrix):\n",
    "        for j, adjacent in enumerate(row):\n",
    "            if adjacent:\n",
    "                adj[i].append(j)\n",
    "        if adj[i].__len__ == 0:\n",
    "            adj[i] = []\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adc45036",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '/gpfs/gibbs/pi/zhao/yw599/Multiome/scGCN/scGCN/input'\n",
    "PIK = \"{}/datasets.dat\".format(datadir)\n",
    "with open(PIK, \"rb\") as f:\n",
    "    objects = pkl.load(f)\n",
    "\n",
    "data_train1, data_test1, data_val1, label_train1, label_test1, label_val1, lab_data2, lab_label2, types = tuple(\n",
    "    objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0933e79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6621/1134355627.py:17: DeprecationWarning: Numeric-style type codes are deprecated and will result in an error in the future.\n",
      "  datas_tr = scipy.sparse.csr_matrix(datas_train.astype('Float64'))\n",
      "/tmp/ipykernel_6621/1134355627.py:18: DeprecationWarning: Numeric-style type codes are deprecated and will result in an error in the future.\n",
      "  datas_va = scipy.sparse.csr_matrix(datas_val.astype('Float64'))\n",
      "/tmp/ipykernel_6621/1134355627.py:19: DeprecationWarning: Numeric-style type codes are deprecated and will result in an error in the future.\n",
      "  datas_te = scipy.sparse.csr_matrix(datas_test.astype('Float64'))\n"
     ]
    }
   ],
   "source": [
    "train2 = pd.concat([data_train1, lab_data2])\n",
    "lab_train2 = pd.concat([label_train1, lab_label2])\n",
    "\n",
    "datas_train = np.array(train2)\n",
    "datas_test = np.array(data_test1)\n",
    "datas_val = np.array(data_val1)\n",
    "\n",
    "index_guide = np.concatenate(\n",
    "    (label_train1.index, lab_label2.index * (-1) - 1, label_val1.index,\n",
    "     label_test1.index))\n",
    "\n",
    "labels_train = np.array(lab_train2).flatten()\n",
    "labels_test = np.array(label_test1).flatten()\n",
    "labels_val = np.array(label_val1).flatten()\n",
    "\n",
    "#' convert pandas data frame to csr_matrix format\n",
    "datas_tr = scipy.sparse.csr_matrix(datas_train.astype('Float64'))\n",
    "datas_va = scipy.sparse.csr_matrix(datas_val.astype('Float64'))\n",
    "datas_te = scipy.sparse.csr_matrix(datas_test.astype('Float64'))\n",
    "\n",
    "#' 3) set the unlabeled data in training set\n",
    "\n",
    "#' @param N; the number of labeled samples in training set\n",
    "M = len(data_train1)\n",
    "\n",
    "#' 4) get the feature object by combining training, test, valiation sets\n",
    "\n",
    "features = sp.vstack((sp.vstack((datas_tr, datas_va)), datas_te)).tolil()\n",
    "features = preprocess_features(features)\n",
    "\n",
    "#' 5) Given cell type, generate three sets of labels with the same dimension\n",
    "labels_tr = labels_train.flatten()\n",
    "labels_va = labels_val.flatten()\n",
    "labels_te = labels_test.flatten()\n",
    "\n",
    "labels = np.concatenate(\n",
    "    [np.concatenate([labels_tr, labels_va]), labels_te])\n",
    "Labels = pd.DataFrame(labels)\n",
    "\n",
    "true_label = Labels\n",
    "#' convert list to binary matrix\n",
    "uniq = np.unique(Labels.values)\n",
    "\n",
    "rename = {}\n",
    "\n",
    "for line in range(0, len(types)):\n",
    "    key = types[line]\n",
    "    rename[key] = int(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb1582aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Label1 = Labels.replace(rename)\n",
    "indices = np.array(Label1.values, dtype='int').tolist()\n",
    "\n",
    "indice = [item for sublist in indices for item in sublist]\n",
    "\n",
    "#' convert list to binary matrix\n",
    "indptr = range(len(indice) + 1)\n",
    "dat = np.ones(len(indice))\n",
    "binary_label = scipy.sparse.csr_matrix((dat, indice, indptr))\n",
    "\n",
    "#' new label with binary values\n",
    "new_label = np.array(binary_label.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f7433f5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.],\n",
       "       [0., 0., 0., ..., 0., 0., 1.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c3dd95f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ductal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>delta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1836</th>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1837</th>\n",
       "      <td>beta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1838</th>\n",
       "      <td>ductal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1839</th>\n",
       "      <td>quiescent_stellate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>ductal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1841 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       0\n",
       "0                   beta\n",
       "1                 ductal\n",
       "2                  delta\n",
       "3                  delta\n",
       "4                   beta\n",
       "...                  ...\n",
       "1836                beta\n",
       "1837                beta\n",
       "1838              ductal\n",
       "1839  quiescent_stellate\n",
       "1840              ductal\n",
       "\n",
       "[1841 rows x 1 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09aa1af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c10b6090",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6621/3022436843.py:56: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  adj = nx.adjacency_matrix(nx.from_dict_of_lists(adj))\n"
     ]
    }
   ],
   "source": [
    "#' ----- construct adjacent matrix ---------\n",
    "\n",
    "id_graph1 = pd.read_csv('{}/inter_graph.csv'.format(datadir),\n",
    "                    index_col=0,\n",
    "                    sep=',')\n",
    "id_graph2 = pd.read_csv('{}/intra_graph.csv'.format(datadir),\n",
    "                    sep=',',\n",
    "                    index_col=0)\n",
    "\n",
    "#' --- map index ----\n",
    "fake1 = np.array([-1] * len(lab_data2.index))\n",
    "index1 = np.concatenate((data_train1.index, fake1, data_val1.index,\n",
    "                     data_test1.index)).flatten()\n",
    "#' (feature_data.index==index1).all()\n",
    "fake2 = np.array([-1] * len(data_train1))\n",
    "fake3 = np.array([-1] * (len(data_val1) + len(data_test1)))\n",
    "find1 = np.concatenate((fake2, np.array(lab_data2.index), fake3)).flatten()\n",
    "\n",
    "#' ---------------------------------------------\n",
    "#'  intra-graph\n",
    "#' ---------------------------------------------\n",
    "id_grp1 = np.array([\n",
    "np.concatenate((np.where(find1 == id_graph2.iloc[i, 1])[0],\n",
    "                np.where(find1 == id_graph2.iloc[i, 0])[0]))\n",
    "for i in range(len(id_graph2))\n",
    "])\n",
    "\n",
    "id_grp2 = np.array([\n",
    "np.concatenate((np.where(find1 == id_graph2.iloc[i, 0])[0],\n",
    "                np.where(find1 == id_graph2.iloc[i, 1])[0]))\n",
    "for i in range(len(id_graph2))\n",
    "])\n",
    "\n",
    "#' ---------------------------------------------\n",
    "#'  inter-graph\n",
    "#' ---------------------------------------------\n",
    "id_gp1 = np.array([\n",
    "    np.concatenate((np.where(find1 == id_graph1.iloc[i, 1])[0],\n",
    "                    np.where(index1 == id_graph1.iloc[i, 0])[0]))\n",
    "    for i in range(len(id_graph1))\n",
    "])\n",
    "\n",
    "id_gp2 = np.array([\n",
    "    np.concatenate((np.where(index1 == id_graph1.iloc[i, 0])[0],\n",
    "                    np.where(find1 == id_graph1.iloc[i, 1])[0]))\n",
    "    for i in range(len(id_graph1))\n",
    "])\n",
    "\n",
    "matrix = np.identity(len(labels))\n",
    "matrix[tuple(id_grp1.T)] = 1\n",
    "matrix[tuple(id_grp2.T)] = 1\n",
    "matrix[tuple(id_gp1.T)] = 1\n",
    "matrix[tuple(id_gp2.T)] = 1\n",
    "\n",
    "adj = graph(matrix)\n",
    "adj = nx.adjacency_matrix(nx.from_dict_of_lists(adj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec355545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1483, 2000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3939e431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix[:1483,1483:3000].sum(1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c0949915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x2 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2 stored elements (1 diagonals) in DIAgonal format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp.eye(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e82c6fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9105, 9105)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7ad9d6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1936, 2)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_graph1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a17d35f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16808, 2)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_graph2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "63f65862",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V1    1839\n",
       "V2    7247\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_graph1.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "62990731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "V1    7263\n",
       "V2    7263\n",
       "dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_graph2.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9f92ec97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7264, 2000)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_data2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "78a618eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1483, 2000)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c86d715b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16808, 2)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_grp1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6649c722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5512c0b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 1 of /gpfs/gibbs/pi/zhao/yw599/conda_envs/tf1/lib/python3.7/site-packages/distutils-precedence.pth:\n",
      "\n",
      "  Traceback (most recent call last):\n",
      "    File \"/gpfs/gibbs/pi/zhao/yw599/conda_envs/tf1/lib/python3.7/site.py\", line 168, in addpackage\n",
      "      exec(line)\n",
      "    File \"<string>\", line 1, in <module>\n",
      "  ModuleNotFoundError: No module named '_distutils_hack'\n",
      "\n",
      "Remainder of file ignored\n",
      "Collecting numpy==1.19.5\n",
      "  Downloading numpy-1.19.5-cp37-cp37m-manylinux2010_x86_64.whl (14.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.21.6\n",
      "    Uninstalling numpy-1.21.6:\n",
      "      Successfully uninstalled numpy-1.21.6\n",
      "Successfully installed numpy-1.19.5\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy==1.19.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7525d8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6943b271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing line 1 of /gpfs/gibbs/pi/zhao/yw599/conda_envs/tf1/lib/python3.7/site-packages/distutils-precedence.pth:\n",
      "\n",
      "  Traceback (most recent call last):\n",
      "    File \"/gpfs/gibbs/pi/zhao/yw599/conda_envs/tf1/lib/python3.7/site.py\", line 168, in addpackage\n",
      "      exec(line)\n",
      "    File \"<string>\", line 1, in <module>\n",
      "  ModuleNotFoundError: No module named '_distutils_hack'\n",
      "\n",
      "Remainder of file ignored\n",
      "train.py:26: SyntaxWarning: assertion is always true, perhaps remove parentheses?\n",
      "  assert(len(sys.argv) == 2, \"parameter needed: output path\")\n",
      "WARNING:tensorflow:From train.py:22: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "(50, 2000) (50, 1) (6, 2000) (6, 1)\n",
      "True\n",
      "True\n",
      "(606, 2000) (606, 1) (68, 2000) (68, 1)\n",
      "True\n",
      "True\n",
      "(36, 2000) (36, 1) (5, 2000) (5, 1)\n",
      "True\n",
      "True\n",
      "(91, 2000) (91, 1) (11, 2000) (11, 1)\n",
      "True\n",
      "True\n",
      "(88, 2000) (88, 1) (10, 2000) (10, 1)\n",
      "True\n",
      "True\n",
      "(99, 2000) (99, 1) (11, 2000) (11, 1)\n",
      "True\n",
      "True\n",
      "(27, 2000) (27, 1) (4, 2000) (4, 1)\n",
      "True\n",
      "True\n",
      "(7, 2000) (7, 1) (1, 2000) (1, 1)\n",
      "True\n",
      "True\n",
      "(30, 2000) (30, 1) (4, 2000) (4, 1)\n",
      "True\n",
      "True\n",
      "(15, 2000) (15, 1) (2, 2000) (2, 1)\n",
      "True\n",
      "True\n",
      "(12, 2000) (12, 1) (2, 2000) (2, 1)\n",
      "True\n",
      "True\n",
      "(230, 2000) (230, 1) (26, 2000) (26, 1)\n",
      "True\n",
      "True\n",
      "(171, 2000) (171, 1) (19, 2000) (19, 1)\n",
      "True\n",
      "True\n",
      "(8, 2000) (8, 1) (1, 2000) (1, 1)\n",
      "True\n",
      "True\n",
      "(18, 2000) (18, 1) (3, 2000) (3, 1)\n",
      "True\n",
      "True\n",
      "(27, 2000) (27, 1) (3, 2000) (3, 1)\n",
      "True\n",
      "True\n",
      "(22, 2000) (22, 1) (3, 2000) (3, 1)\n",
      "True\n",
      "True\n",
      "(49, 2000) (49, 1) (6, 2000) (6, 1)\n",
      "True\n",
      "True\n",
      "load data succesfully....\n",
      "assign input coordinatly....\n",
      "WARNING:tensorflow:From train.py:59: The name tf.sparse_placeholder is deprecated. Please use tf.compat.v1.sparse_placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From train.py:64: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From train.py:68: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/gibbs/pi/zhao/yw599/scGCN/scGCN/models.py:94: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/gibbs/pi/zhao/yw599/scGCN/scGCN/models.py:40: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/gibbs/pi/zhao/yw599/scGCN/scGCN/utils.py:239: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/gibbs/pi/zhao/yw599/scGCN/scGCN/layers.py:68: The name tf.summary.histogram is deprecated. Please use tf.compat.v1.summary.histogram instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/gibbs/pi/zhao/yw599/scGCN/scGCN/layers.py:26: The name tf.sparse_retain is deprecated. Please use tf.sparse.retain instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/gibbs/pi/zhao/yw599/scGCN/scGCN/layers.py:33: The name tf.sparse_tensor_dense_matmul is deprecated. Please use tf.sparse.sparse_dense_matmul instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/gibbs/pi/zhao/yw599/scGCN/scGCN/layers.py:107: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /gpfs/gibbs/pi/zhao/yw599/scGCN/scGCN/models.py:51: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/gibbs/pi/zhao/yw599/scGCN/scGCN/models.py:51: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "WARNING:tensorflow:From /gpfs/gibbs/pi/zhao/yw599/scGCN/scGCN/utils.py:210: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "WARNING:tensorflow:From train.py:87: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "2022-07-17 23:49:42.786777: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2022-07-17 23:49:42.803050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n",
      "name: NVIDIA GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\n",
      "pciBusID: 0000:02:00.0\n",
      "2022-07-17 23:49:42.803249: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory\n",
      "2022-07-17 23:49:42.803376: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory\n",
      "2022-07-17 23:49:42.805491: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory\n",
      "2022-07-17 23:49:42.805591: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory\n",
      "2022-07-17 23:49:42.805723: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory\n",
      "2022-07-17 23:49:42.805833: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory\n",
      "2022-07-17 23:49:42.805921: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory\n",
      "2022-07-17 23:49:42.805936: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1641] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-07-17 23:49:42.806317: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2022-07-17 23:49:42.812436: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3499740000 Hz\n",
      "2022-07-17 23:49:42.812557: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f2ad0d7690 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-07-17 23:49:42.812575: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-07-17 23:49:42.924494: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f2ad0d9da0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-07-17 23:49:42.924564: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2022-07-17 23:49:42.924672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-07-17 23:49:42.924687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      \n",
      "WARNING:tensorflow:From train.py:89: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From train.py:101: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "Epoch: 0001 train_loss= 2.89051 train_acc= 0.02963 val_loss= 2.88403 val_acc= 0.24865 time= 0.61990\n",
      "Epoch: 0002 train_loss= 2.88378 train_acc= 0.24716 val_loss= 2.87548 val_acc= 0.36757 time= 0.50390\n",
      "Epoch: 0003 train_loss= 2.87486 train_acc= 0.38588 val_loss= 2.86492 val_acc= 0.36757 time= 0.51042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0004 train_loss= 2.86380 train_acc= 0.38335 val_loss= 2.85217 val_acc= 0.36757 time= 0.51461\n",
      "Epoch: 0005 train_loss= 2.85044 train_acc= 0.38335 val_loss= 2.83712 val_acc= 0.36757 time= 0.50541\n",
      "Epoch: 0006 train_loss= 2.83467 train_acc= 0.38335 val_loss= 2.81968 val_acc= 0.36757 time= 0.51383\n",
      "Epoch: 0007 train_loss= 2.81638 train_acc= 0.38335 val_loss= 2.79970 val_acc= 0.36757 time= 0.50474\n",
      "Epoch: 0008 train_loss= 2.79541 train_acc= 0.38335 val_loss= 2.77715 val_acc= 0.36757 time= 0.51354\n",
      "Epoch: 0009 train_loss= 2.77169 train_acc= 0.38335 val_loss= 2.75200 val_acc= 0.36757 time= 0.50526\n",
      "Epoch: 0010 train_loss= 2.74523 train_acc= 0.38335 val_loss= 2.72433 val_acc= 0.36757 time= 0.50737\n",
      "Epoch: 0011 train_loss= 2.71608 train_acc= 0.38335 val_loss= 2.69436 val_acc= 0.36757 time= 0.51056\n",
      "Epoch: 0012 train_loss= 2.68446 train_acc= 0.38335 val_loss= 2.66206 val_acc= 0.36757 time= 0.51042\n",
      "Epoch: 0013 train_loss= 2.65033 train_acc= 0.38335 val_loss= 2.62752 val_acc= 0.36757 time= 0.50751\n",
      "Epoch: 0014 train_loss= 2.61378 train_acc= 0.38335 val_loss= 2.59100 val_acc= 0.36757 time= 0.51509\n",
      "Epoch: 0015 train_loss= 2.57508 train_acc= 0.38335 val_loss= 2.55283 val_acc= 0.36757 time= 0.50921\n",
      "Epoch: 0016 train_loss= 2.53454 train_acc= 0.38335 val_loss= 2.51341 val_acc= 0.36757 time= 0.50899\n",
      "Epoch: 0017 train_loss= 2.49260 train_acc= 0.38335 val_loss= 2.47326 val_acc= 0.36757 time= 0.50445\n",
      "Epoch: 0018 train_loss= 2.44977 train_acc= 0.38335 val_loss= 2.43298 val_acc= 0.36757 time= 0.50695\n",
      "Epoch: 0019 train_loss= 2.40666 train_acc= 0.38335 val_loss= 2.39324 val_acc= 0.36757 time= 0.50822\n",
      "Epoch: 0020 train_loss= 2.36397 train_acc= 0.38272 val_loss= 2.35474 val_acc= 0.36757 time= 0.50779\n",
      "Epoch: 0021 train_loss= 2.32242 train_acc= 0.38272 val_loss= 2.31819 val_acc= 0.36757 time= 0.50427\n",
      "Epoch: 0022 train_loss= 2.28276 train_acc= 0.38272 val_loss= 2.28420 val_acc= 0.36757 time= 0.50611\n",
      "Epoch: 0023 train_loss= 2.24564 train_acc= 0.38209 val_loss= 2.25328 val_acc= 0.36757 time= 0.50510\n",
      "Epoch: 0024 train_loss= 2.21159 train_acc= 0.38209 val_loss= 2.22569 val_acc= 0.36757 time= 0.51210\n",
      "Epoch: 0025 train_loss= 2.18093 train_acc= 0.38209 val_loss= 2.20165 val_acc= 0.36757 time= 0.50406\n",
      "Epoch: 0026 train_loss= 2.15391 train_acc= 0.38209 val_loss= 2.18119 val_acc= 0.36757 time= 0.50792\n",
      "Epoch: 0027 train_loss= 2.13060 train_acc= 0.38209 val_loss= 2.16406 val_acc= 0.36757 time= 0.50502\n",
      "Epoch: 0028 train_loss= 2.11075 train_acc= 0.38209 val_loss= 2.14984 val_acc= 0.36757 time= 0.50734\n",
      "Epoch: 0029 train_loss= 2.09399 train_acc= 0.38209 val_loss= 2.13796 val_acc= 0.36757 time= 0.50510\n",
      "Epoch: 0030 train_loss= 2.07980 train_acc= 0.38209 val_loss= 2.12770 val_acc= 0.36757 time= 0.50663\n",
      "Epoch: 0031 train_loss= 2.06750 train_acc= 0.38209 val_loss= 2.11845 val_acc= 0.36757 time= 0.50544\n",
      "Epoch: 0032 train_loss= 2.05643 train_acc= 0.38209 val_loss= 2.10946 val_acc= 0.36757 time= 0.50700\n",
      "Epoch: 0033 train_loss= 2.04593 train_acc= 0.38209 val_loss= 2.10022 val_acc= 0.36757 time= 0.50480\n",
      "Epoch: 0034 train_loss= 2.03544 train_acc= 0.38209 val_loss= 2.09034 val_acc= 0.36757 time= 0.51367\n",
      "Epoch: 0035 train_loss= 2.02457 train_acc= 0.38209 val_loss= 2.07928 val_acc= 0.36757 time= 0.50464\n",
      "Epoch: 0036 train_loss= 2.01279 train_acc= 0.38209 val_loss= 2.06681 val_acc= 0.36757 time= 0.50677\n",
      "Epoch: 0037 train_loss= 1.99985 train_acc= 0.38209 val_loss= 2.05293 val_acc= 0.36757 time= 0.50485\n",
      "Epoch: 0038 train_loss= 1.98572 train_acc= 0.38209 val_loss= 2.03779 val_acc= 0.36757 time= 0.50833\n",
      "Epoch: 0039 train_loss= 1.97055 train_acc= 0.38209 val_loss= 2.02161 val_acc= 0.36757 time= 0.50406\n",
      "Epoch: 0040 train_loss= 1.95454 train_acc= 0.38209 val_loss= 2.00468 val_acc= 0.36757 time= 0.50682\n",
      "Epoch: 0041 train_loss= 1.93795 train_acc= 0.38209 val_loss= 1.98726 val_acc= 0.36757 time= 0.51304\n",
      "Epoch: 0042 train_loss= 1.92101 train_acc= 0.38209 val_loss= 1.96956 val_acc= 0.36757 time= 0.50774\n",
      "Epoch: 0043 train_loss= 1.90391 train_acc= 0.38209 val_loss= 1.95175 val_acc= 0.36757 time= 0.50726\n",
      "Epoch: 0044 train_loss= 1.88679 train_acc= 0.38209 val_loss= 1.93392 val_acc= 0.36757 time= 0.50898\n",
      "Epoch: 0045 train_loss= 1.86970 train_acc= 0.38209 val_loss= 1.91611 val_acc= 0.36757 time= 0.50743\n",
      "Epoch: 0046 train_loss= 1.85268 train_acc= 0.38272 val_loss= 1.89830 val_acc= 0.36757 time= 0.50842\n",
      "Epoch: 0047 train_loss= 1.83568 train_acc= 0.38335 val_loss= 1.88047 val_acc= 0.36757 time= 0.50491\n",
      "Epoch: 0048 train_loss= 1.81865 train_acc= 0.38335 val_loss= 1.86256 val_acc= 0.36757 time= 0.50789\n",
      "Epoch: 0049 train_loss= 1.80152 train_acc= 0.38525 val_loss= 1.84454 val_acc= 0.37297 time= 0.50560\n",
      "Epoch: 0050 train_loss= 1.78422 train_acc= 0.39092 val_loss= 1.82636 val_acc= 0.38919 time= 0.50820\n",
      "Epoch: 0051 train_loss= 1.76671 train_acc= 0.39849 val_loss= 1.80803 val_acc= 0.40541 time= 0.50744\n",
      "Epoch: 0052 train_loss= 1.74894 train_acc= 0.41551 val_loss= 1.78953 val_acc= 0.44324 time= 0.50716\n",
      "Epoch: 0053 train_loss= 1.73094 train_acc= 0.46280 val_loss= 1.77090 val_acc= 0.48108 time= 0.50445\n",
      "Epoch: 0054 train_loss= 1.71271 train_acc= 0.50189 val_loss= 1.75220 val_acc= 0.49730 time= 0.50983\n",
      "Epoch: 0055 train_loss= 1.69432 train_acc= 0.51513 val_loss= 1.73346 val_acc= 0.50270 time= 0.50890\n",
      "Epoch: 0056 train_loss= 1.67580 train_acc= 0.52963 val_loss= 1.71474 val_acc= 0.51892 time= 0.50742\n",
      "Epoch: 0057 train_loss= 1.65722 train_acc= 0.54351 val_loss= 1.69609 val_acc= 0.52432 time= 0.50337\n",
      "Epoch: 0058 train_loss= 1.63861 train_acc= 0.55422 val_loss= 1.67751 val_acc= 0.54054 time= 0.50776\n",
      "Epoch: 0059 train_loss= 1.62003 train_acc= 0.56873 val_loss= 1.65904 val_acc= 0.54054 time= 0.50888\n",
      "Epoch: 0060 train_loss= 1.60150 train_acc= 0.57503 val_loss= 1.64069 val_acc= 0.54054 time= 0.50694\n",
      "Epoch: 0061 train_loss= 1.58306 train_acc= 0.58071 val_loss= 1.62247 val_acc= 0.54595 time= 0.50445\n",
      "Epoch: 0062 train_loss= 1.56472 train_acc= 0.58701 val_loss= 1.60440 val_acc= 0.55135 time= 0.50702\n",
      "Epoch: 0063 train_loss= 1.54653 train_acc= 0.59016 val_loss= 1.58650 val_acc= 0.55135 time= 0.50385\n",
      "Epoch: 0064 train_loss= 1.52849 train_acc= 0.59206 val_loss= 1.56878 val_acc= 0.55676 time= 0.50677\n",
      "Epoch: 0065 train_loss= 1.51064 train_acc= 0.59395 val_loss= 1.55125 val_acc= 0.56216 time= 0.50345\n",
      "Epoch: 0066 train_loss= 1.49301 train_acc= 0.59521 val_loss= 1.53393 val_acc= 0.56216 time= 0.50602\n",
      "Epoch: 0067 train_loss= 1.47561 train_acc= 0.59647 val_loss= 1.51684 val_acc= 0.56216 time= 0.50305\n",
      "Epoch: 0068 train_loss= 1.45847 train_acc= 0.59899 val_loss= 1.49997 val_acc= 0.57297 time= 0.50646\n",
      "Epoch: 0069 train_loss= 1.44160 train_acc= 0.60025 val_loss= 1.48335 val_acc= 0.57297 time= 0.50179\n",
      "Epoch: 0070 train_loss= 1.42502 train_acc= 0.60214 val_loss= 1.46696 val_acc= 0.57297 time= 0.50826\n",
      "Epoch: 0071 train_loss= 1.40874 train_acc= 0.60340 val_loss= 1.45083 val_acc= 0.57297 time= 0.50947\n",
      "Epoch: 0072 train_loss= 1.39277 train_acc= 0.60404 val_loss= 1.43494 val_acc= 0.57297 time= 0.50587\n",
      "Epoch: 0073 train_loss= 1.37710 train_acc= 0.60467 val_loss= 1.41933 val_acc= 0.57297 time= 0.50411\n",
      "Epoch: 0074 train_loss= 1.36173 train_acc= 0.60656 val_loss= 1.40396 val_acc= 0.57297 time= 0.50738\n",
      "Epoch: 0075 train_loss= 1.34666 train_acc= 0.60782 val_loss= 1.38885 val_acc= 0.57297 time= 0.50312\n",
      "Epoch: 0076 train_loss= 1.33188 train_acc= 0.60908 val_loss= 1.37399 val_acc= 0.57297 time= 0.50659\n",
      "Epoch: 0077 train_loss= 1.31739 train_acc= 0.61097 val_loss= 1.35939 val_acc= 0.57838 time= 0.50403\n",
      "Epoch: 0078 train_loss= 1.30319 train_acc= 0.61160 val_loss= 1.34505 val_acc= 0.57838 time= 0.50571\n",
      "Epoch: 0079 train_loss= 1.28927 train_acc= 0.61160 val_loss= 1.33097 val_acc= 0.58378 time= 0.50309\n",
      "Epoch: 0080 train_loss= 1.27562 train_acc= 0.61349 val_loss= 1.31717 val_acc= 0.58378 time= 0.50689\n",
      "Epoch: 0081 train_loss= 1.26226 train_acc= 0.61412 val_loss= 1.30364 val_acc= 0.58919 time= 0.50496\n",
      "Epoch: 0082 train_loss= 1.24918 train_acc= 0.61538 val_loss= 1.29036 val_acc= 0.59459 time= 0.50797\n",
      "Epoch: 0083 train_loss= 1.23637 train_acc= 0.61538 val_loss= 1.27736 val_acc= 0.59459 time= 0.50354\n",
      "Epoch: 0084 train_loss= 1.22383 train_acc= 0.61917 val_loss= 1.26459 val_acc= 0.60000 time= 0.50625\n",
      "Epoch: 0085 train_loss= 1.21157 train_acc= 0.61917 val_loss= 1.25206 val_acc= 0.60000 time= 0.50477\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0086 train_loss= 1.19957 train_acc= 0.61980 val_loss= 1.23980 val_acc= 0.60000 time= 0.50644\n",
      "Epoch: 0087 train_loss= 1.18782 train_acc= 0.62043 val_loss= 1.22778 val_acc= 0.60000 time= 0.50823\n",
      "Epoch: 0088 train_loss= 1.17631 train_acc= 0.62232 val_loss= 1.21600 val_acc= 0.60000 time= 0.50607\n",
      "Epoch: 0089 train_loss= 1.16504 train_acc= 0.62547 val_loss= 1.20444 val_acc= 0.60541 time= 0.50341\n",
      "Epoch: 0090 train_loss= 1.15400 train_acc= 0.62547 val_loss= 1.19309 val_acc= 0.60541 time= 0.50628\n",
      "Epoch: 0091 train_loss= 1.14318 train_acc= 0.62736 val_loss= 1.18197 val_acc= 0.61622 time= 0.50436\n",
      "Epoch: 0092 train_loss= 1.13258 train_acc= 0.62926 val_loss= 1.17107 val_acc= 0.61622 time= 0.50614\n",
      "Epoch: 0093 train_loss= 1.12218 train_acc= 0.63367 val_loss= 1.16038 val_acc= 0.61622 time= 0.50459\n",
      "Epoch: 0094 train_loss= 1.11198 train_acc= 0.63682 val_loss= 1.14989 val_acc= 0.62162 time= 0.50826\n",
      "Epoch: 0095 train_loss= 1.10196 train_acc= 0.63934 val_loss= 1.13960 val_acc= 0.62162 time= 0.50987\n",
      "Epoch: 0096 train_loss= 1.09213 train_acc= 0.64060 val_loss= 1.12951 val_acc= 0.62162 time= 0.50795\n",
      "Epoch: 0097 train_loss= 1.08248 train_acc= 0.64187 val_loss= 1.11962 val_acc= 0.62703 time= 0.50325\n",
      "Epoch: 0098 train_loss= 1.07301 train_acc= 0.64628 val_loss= 1.10992 val_acc= 0.62703 time= 0.50655\n",
      "Epoch: 0099 train_loss= 1.06371 train_acc= 0.65006 val_loss= 1.10040 val_acc= 0.63784 time= 0.50338\n",
      "Epoch: 0100 train_loss= 1.05458 train_acc= 0.65385 val_loss= 1.09107 val_acc= 0.63784 time= 0.50706\n",
      "Epoch: 0101 train_loss= 1.04560 train_acc= 0.65700 val_loss= 1.08192 val_acc= 0.64865 time= 0.50975\n",
      "Epoch: 0102 train_loss= 1.03678 train_acc= 0.66330 val_loss= 1.07294 val_acc= 0.64865 time= 0.50604\n",
      "Epoch: 0103 train_loss= 1.02811 train_acc= 0.66835 val_loss= 1.06411 val_acc= 0.64865 time= 0.50378\n",
      "Epoch: 0104 train_loss= 1.01959 train_acc= 0.67087 val_loss= 1.05542 val_acc= 0.65405 time= 0.50699\n",
      "Epoch: 0105 train_loss= 1.01121 train_acc= 0.67402 val_loss= 1.04690 val_acc= 0.65946 time= 0.50393\n",
      "Epoch: 0106 train_loss= 1.00297 train_acc= 0.68033 val_loss= 1.03851 val_acc= 0.66486 time= 0.50703\n",
      "Epoch: 0107 train_loss= 0.99486 train_acc= 0.68285 val_loss= 1.03026 val_acc= 0.67027 time= 0.50324\n",
      "Epoch: 0108 train_loss= 0.98689 train_acc= 0.68789 val_loss= 1.02214 val_acc= 0.67027 time= 0.50600\n",
      "Epoch: 0109 train_loss= 0.97905 train_acc= 0.68978 val_loss= 1.01415 val_acc= 0.67568 time= 0.50457\n",
      "Epoch: 0110 train_loss= 0.97133 train_acc= 0.69168 val_loss= 1.00629 val_acc= 0.67568 time= 0.50694\n",
      "Epoch: 0111 train_loss= 0.96374 train_acc= 0.69420 val_loss= 0.99856 val_acc= 0.68108 time= 0.50872\n",
      "Epoch: 0112 train_loss= 0.95626 train_acc= 0.69798 val_loss= 0.99095 val_acc= 0.68108 time= 0.50588\n",
      "Epoch: 0113 train_loss= 0.94888 train_acc= 0.69861 val_loss= 0.98346 val_acc= 0.68108 time= 0.50342\n",
      "Epoch: 0114 train_loss= 0.94162 train_acc= 0.70366 val_loss= 0.97608 val_acc= 0.68649 time= 0.50755\n",
      "Epoch: 0115 train_loss= 0.93447 train_acc= 0.70618 val_loss= 0.96882 val_acc= 0.68649 time= 0.50389\n",
      "Epoch: 0116 train_loss= 0.92743 train_acc= 0.70870 val_loss= 0.96167 val_acc= 0.69189 time= 0.50695\n",
      "Epoch: 0117 train_loss= 0.92048 train_acc= 0.71374 val_loss= 0.95463 val_acc= 0.69189 time= 0.50331\n",
      "Epoch: 0118 train_loss= 0.91364 train_acc= 0.71816 val_loss= 0.94771 val_acc= 0.69189 time= 0.50663\n",
      "Epoch: 0119 train_loss= 0.90690 train_acc= 0.72068 val_loss= 0.94088 val_acc= 0.69730 time= 0.50369\n",
      "Epoch: 0120 train_loss= 0.90025 train_acc= 0.72320 val_loss= 0.93416 val_acc= 0.70270 time= 0.50886\n",
      "Epoch: 0121 train_loss= 0.89370 train_acc= 0.72825 val_loss= 0.92755 val_acc= 0.71351 time= 0.50917\n",
      "Epoch: 0122 train_loss= 0.88725 train_acc= 0.73077 val_loss= 0.92104 val_acc= 0.72432 time= 0.50674\n",
      "Epoch: 0123 train_loss= 0.88089 train_acc= 0.73455 val_loss= 0.91463 val_acc= 0.72973 time= 0.50324\n",
      "Epoch: 0124 train_loss= 0.87463 train_acc= 0.73581 val_loss= 0.90832 val_acc= 0.72973 time= 0.50595\n",
      "Epoch: 0125 train_loss= 0.86846 train_acc= 0.73770 val_loss= 0.90211 val_acc= 0.72973 time= 0.50351\n",
      "Epoch: 0126 train_loss= 0.86238 train_acc= 0.73833 val_loss= 0.89601 val_acc= 0.74054 time= 0.50638\n",
      "Epoch: 0127 train_loss= 0.85638 train_acc= 0.74275 val_loss= 0.89001 val_acc= 0.75135 time= 0.50221\n",
      "Epoch: 0128 train_loss= 0.85048 train_acc= 0.74338 val_loss= 0.88410 val_acc= 0.75135 time= 0.50633\n",
      "Epoch: 0129 train_loss= 0.84465 train_acc= 0.74527 val_loss= 0.87829 val_acc= 0.75676 time= 0.50298\n",
      "Epoch: 0130 train_loss= 0.83891 train_acc= 0.74716 val_loss= 0.87257 val_acc= 0.76216 time= 0.50601\n",
      "Epoch: 0131 train_loss= 0.83324 train_acc= 0.74905 val_loss= 0.86693 val_acc= 0.76757 time= 0.50299\n",
      "Epoch: 0132 train_loss= 0.82765 train_acc= 0.75094 val_loss= 0.86138 val_acc= 0.76757 time= 0.50704\n",
      "Epoch: 0133 train_loss= 0.82214 train_acc= 0.75221 val_loss= 0.85592 val_acc= 0.76757 time= 0.50871\n",
      "Epoch: 0134 train_loss= 0.81670 train_acc= 0.75410 val_loss= 0.85053 val_acc= 0.77297 time= 0.50726\n",
      "Epoch: 0135 train_loss= 0.81133 train_acc= 0.75410 val_loss= 0.84523 val_acc= 0.77838 time= 0.50555\n",
      "Epoch: 0136 train_loss= 0.80603 train_acc= 0.75599 val_loss= 0.84000 val_acc= 0.77838 time= 0.50660\n",
      "Epoch: 0137 train_loss= 0.80081 train_acc= 0.75851 val_loss= 0.83485 val_acc= 0.77838 time= 0.50246\n",
      "Epoch: 0138 train_loss= 0.79565 train_acc= 0.75914 val_loss= 0.82978 val_acc= 0.77838 time= 0.50677\n",
      "Epoch: 0139 train_loss= 0.79056 train_acc= 0.75914 val_loss= 0.82477 val_acc= 0.77838 time= 0.50365\n",
      "Epoch: 0140 train_loss= 0.78553 train_acc= 0.75977 val_loss= 0.81985 val_acc= 0.77838 time= 0.50678\n",
      "Epoch: 0141 train_loss= 0.78057 train_acc= 0.76040 val_loss= 0.81499 val_acc= 0.77838 time= 0.50355\n",
      "Epoch: 0142 train_loss= 0.77567 train_acc= 0.76040 val_loss= 0.81020 val_acc= 0.77838 time= 0.50601\n",
      "Epoch: 0143 train_loss= 0.77083 train_acc= 0.76229 val_loss= 0.80548 val_acc= 0.77838 time= 0.50309\n",
      "Epoch: 0144 train_loss= 0.76605 train_acc= 0.76355 val_loss= 0.80084 val_acc= 0.77838 time= 0.51070\n",
      "Epoch: 0145 train_loss= 0.76132 train_acc= 0.76419 val_loss= 0.79625 val_acc= 0.77838 time= 0.50583\n",
      "Epoch: 0146 train_loss= 0.75666 train_acc= 0.76608 val_loss= 0.79174 val_acc= 0.77838 time= 0.50648\n",
      "Epoch: 0147 train_loss= 0.75205 train_acc= 0.76797 val_loss= 0.78728 val_acc= 0.77838 time= 0.50647\n",
      "Epoch: 0148 train_loss= 0.74749 train_acc= 0.76923 val_loss= 0.78288 val_acc= 0.77838 time= 0.50736\n",
      "Epoch: 0149 train_loss= 0.74299 train_acc= 0.77049 val_loss= 0.77855 val_acc= 0.77838 time= 0.50353\n",
      "Epoch: 0150 train_loss= 0.73854 train_acc= 0.77238 val_loss= 0.77427 val_acc= 0.77838 time= 0.50847\n",
      "Epoch: 0151 train_loss= 0.73414 train_acc= 0.77238 val_loss= 0.77004 val_acc= 0.77838 time= 0.50333\n",
      "Epoch: 0152 train_loss= 0.72979 train_acc= 0.77364 val_loss= 0.76588 val_acc= 0.77838 time= 0.50753\n",
      "Epoch: 0153 train_loss= 0.72549 train_acc= 0.77490 val_loss= 0.76176 val_acc= 0.77838 time= 0.50535\n",
      "Epoch: 0154 train_loss= 0.72123 train_acc= 0.77427 val_loss= 0.75770 val_acc= 0.77838 time= 0.50657\n",
      "Epoch: 0155 train_loss= 0.71702 train_acc= 0.77553 val_loss= 0.75370 val_acc= 0.77838 time= 0.50400\n",
      "Epoch: 0156 train_loss= 0.71285 train_acc= 0.77553 val_loss= 0.74974 val_acc= 0.77838 time= 0.50455\n",
      "Epoch: 0157 train_loss= 0.70873 train_acc= 0.77617 val_loss= 0.74584 val_acc= 0.77838 time= 0.51375\n",
      "Epoch: 0158 train_loss= 0.70465 train_acc= 0.77806 val_loss= 0.74197 val_acc= 0.77838 time= 0.50601\n",
      "Epoch: 0159 train_loss= 0.70061 train_acc= 0.77869 val_loss= 0.73815 val_acc= 0.77838 time= 0.50505\n",
      "Epoch: 0160 train_loss= 0.69662 train_acc= 0.78058 val_loss= 0.73438 val_acc= 0.78378 time= 0.50799\n",
      "Epoch: 0161 train_loss= 0.69266 train_acc= 0.78373 val_loss= 0.73066 val_acc= 0.78378 time= 0.50524\n",
      "Epoch: 0162 train_loss= 0.68874 train_acc= 0.78499 val_loss= 0.72698 val_acc= 0.78378 time= 0.50833\n",
      "Epoch: 0163 train_loss= 0.68486 train_acc= 0.78562 val_loss= 0.72335 val_acc= 0.78378 time= 0.50409\n",
      "Epoch: 0164 train_loss= 0.68101 train_acc= 0.78751 val_loss= 0.71976 val_acc= 0.78378 time= 0.50802\n",
      "Epoch: 0165 train_loss= 0.67720 train_acc= 0.78814 val_loss= 0.71621 val_acc= 0.78378 time= 0.50483\n",
      "Epoch: 0166 train_loss= 0.67343 train_acc= 0.78878 val_loss= 0.71271 val_acc= 0.78378 time= 0.50705\n",
      "Epoch: 0167 train_loss= 0.66969 train_acc= 0.78941 val_loss= 0.70924 val_acc= 0.78378 time= 0.50662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0168 train_loss= 0.66598 train_acc= 0.78941 val_loss= 0.70581 val_acc= 0.78378 time= 0.50723\n",
      "Epoch: 0169 train_loss= 0.66230 train_acc= 0.79067 val_loss= 0.70242 val_acc= 0.78378 time= 0.50347\n",
      "Epoch: 0170 train_loss= 0.65865 train_acc= 0.79067 val_loss= 0.69907 val_acc= 0.78378 time= 0.50958\n",
      "Epoch: 0171 train_loss= 0.65503 train_acc= 0.79067 val_loss= 0.69575 val_acc= 0.78378 time= 0.50357\n",
      "Epoch: 0172 train_loss= 0.65145 train_acc= 0.79130 val_loss= 0.69246 val_acc= 0.78378 time= 0.51285\n",
      "Epoch: 0173 train_loss= 0.64789 train_acc= 0.79256 val_loss= 0.68921 val_acc= 0.78919 time= 0.50317\n",
      "Epoch: 0174 train_loss= 0.64436 train_acc= 0.79382 val_loss= 0.68599 val_acc= 0.78919 time= 0.50780\n",
      "Epoch: 0175 train_loss= 0.64085 train_acc= 0.79445 val_loss= 0.68280 val_acc= 0.78919 time= 0.50322\n",
      "Epoch: 0176 train_loss= 0.63737 train_acc= 0.79508 val_loss= 0.67965 val_acc= 0.79459 time= 0.50626\n",
      "Epoch: 0177 train_loss= 0.63391 train_acc= 0.79571 val_loss= 0.67652 val_acc= 0.79459 time= 0.50292\n",
      "Epoch: 0178 train_loss= 0.63048 train_acc= 0.79823 val_loss= 0.67343 val_acc= 0.79459 time= 0.50532\n",
      "Epoch: 0179 train_loss= 0.62707 train_acc= 0.80012 val_loss= 0.67037 val_acc= 0.79459 time= 0.50329\n",
      "Epoch: 0180 train_loss= 0.62369 train_acc= 0.80139 val_loss= 0.66733 val_acc= 0.79459 time= 0.50710\n",
      "Epoch: 0181 train_loss= 0.62032 train_acc= 0.80328 val_loss= 0.66433 val_acc= 0.80000 time= 0.50349\n",
      "Epoch: 0182 train_loss= 0.61698 train_acc= 0.80517 val_loss= 0.66136 val_acc= 0.80000 time= 0.50669\n",
      "Epoch: 0183 train_loss= 0.61366 train_acc= 0.80706 val_loss= 0.65842 val_acc= 0.80000 time= 0.50350\n",
      "Epoch: 0184 train_loss= 0.61036 train_acc= 0.80769 val_loss= 0.65550 val_acc= 0.80000 time= 0.50741\n",
      "Epoch: 0185 train_loss= 0.60708 train_acc= 0.80832 val_loss= 0.65261 val_acc= 0.80000 time= 0.50326\n",
      "Epoch: 0186 train_loss= 0.60381 train_acc= 0.81021 val_loss= 0.64974 val_acc= 0.80000 time= 0.50651\n",
      "Epoch: 0187 train_loss= 0.60057 train_acc= 0.81021 val_loss= 0.64691 val_acc= 0.80000 time= 0.51993\n",
      "Epoch: 0188 train_loss= 0.59734 train_acc= 0.81337 val_loss= 0.64409 val_acc= 0.80000 time= 0.50694\n",
      "Epoch: 0189 train_loss= 0.59414 train_acc= 0.81463 val_loss= 0.64130 val_acc= 0.80000 time= 0.50324\n",
      "Epoch: 0190 train_loss= 0.59094 train_acc= 0.81589 val_loss= 0.63853 val_acc= 0.80000 time= 0.50843\n",
      "Epoch: 0191 train_loss= 0.58777 train_acc= 0.81715 val_loss= 0.63578 val_acc= 0.80000 time= 0.50515\n",
      "Epoch: 0192 train_loss= 0.58461 train_acc= 0.82030 val_loss= 0.63306 val_acc= 0.80541 time= 0.50693\n",
      "Epoch: 0193 train_loss= 0.58147 train_acc= 0.82093 val_loss= 0.63036 val_acc= 0.80541 time= 0.50576\n",
      "Epoch: 0194 train_loss= 0.57834 train_acc= 0.82093 val_loss= 0.62767 val_acc= 0.80541 time= 0.50867\n",
      "Epoch: 0195 train_loss= 0.57523 train_acc= 0.82156 val_loss= 0.62501 val_acc= 0.80541 time= 0.50475\n",
      "Epoch: 0196 train_loss= 0.57214 train_acc= 0.82408 val_loss= 0.62237 val_acc= 0.80541 time= 0.50683\n",
      "Epoch: 0197 train_loss= 0.56905 train_acc= 0.82535 val_loss= 0.61975 val_acc= 0.80541 time= 0.50358\n",
      "Epoch: 0198 train_loss= 0.56599 train_acc= 0.82598 val_loss= 0.61715 val_acc= 0.80541 time= 0.50741\n",
      "Epoch: 0199 train_loss= 0.56293 train_acc= 0.82724 val_loss= 0.61457 val_acc= 0.80541 time= 0.50406\n",
      "Epoch: 0200 train_loss= 0.55989 train_acc= 0.82913 val_loss= 0.61201 val_acc= 0.80541 time= 0.50841\n",
      "Finished Training....\n",
      "Checking train/val set accuracy: 0.8291298865069356, 0.8054054054054054\n"
     ]
    }
   ],
   "source": [
    "! python train.py results\n",
    "# run scGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9752f27e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
